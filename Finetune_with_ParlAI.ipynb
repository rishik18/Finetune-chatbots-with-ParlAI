{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Final Project- Finetuning of Blenderbot 90M on Daily dialog, ConvAi2 and Wizard of Wikipedia datasets\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Name: Hrishikesh Kanade\n",
        "## CWID: 20008801\n",
        "\n",
        "\n",
        "---\n",
        "Key references\n",
        "1. Roller, Stephen, et al. \"Recipes for building an open-domain chatbot.\" arXiv preprint arXiv:2004.13637 (2020).\n",
        "2. Rashkin, Hannah, et al. \"Towards empathetic open-domain conversation models: A new benchmark and dataset.\" arXiv preprint arXiv:1811.00207 (2018).\n",
        "9\n",
        "3. Zhang, Saizheng, et al. \"Personalizing dialogue agents: I have a dog, do you have pets too?.\" arXiv preprint arXiv:1801.07243 (2018).\n",
        "4. Dinan, Emily, et al. \"Wizard of wikipedia: Knowledge-powered conversational agents.\" arXiv preprint arXiv:1811.01241 (2018).\n",
        "5. Smith, Eric Michael, et al. \"Can you put it all together: Evaluating conversational agents' ability to blend skills.\" arXiv preprint arXiv:2004.08449 (2020).\n",
        "6. GPT4\n"
      ],
      "metadata": {
        "id": "Cg86BqkfhnOe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup ParlAI and install pre-requisites"
      ],
      "metadata": {
        "id": "jrKJTo8ngubq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "6vIGhYPN_fn6",
        "outputId": "c62eab27-6ba2-40b7-cdb3-e26116b83bb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 13 02:36:09 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    23W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export CUDA_VISIBLE_DEVICES=0"
      ],
      "metadata": {
        "id": "SJwiC19zlfX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone into ParlAI repo"
      ],
      "metadata": {
        "id": "2USH7n7cg2Yz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdy3d3TfIY6_",
        "outputId": "aaed89a2-61b1-424f-e460-7c5287d7c6bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ParlAI'...\n",
            "remote: Enumerating objects: 48019, done.\u001b[K\n",
            "remote: Counting objects: 100% (534/534), done.\u001b[K\n",
            "remote: Compressing objects: 100% (342/342), done.\u001b[K\n",
            "remote: Total 48019 (delta 247), reused 390 (delta 167), pack-reused 47485\u001b[K\n",
            "Receiving objects: 100% (48019/48019), 145.80 MiB | 16.25 MiB/s, done.\n",
            "Resolving deltas: 100% (34051/34051), done.\n",
            "/content/ParlAI\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/ParlAI.git\n",
        "%cd ParlAI/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DXgMKE4Ih56",
        "outputId": "252791c6-c376-4537-afef-5c59adcfa72c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running develop\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "creating parlai.egg-info\n",
            "writing parlai.egg-info/PKG-INFO\n",
            "writing dependency_links to parlai.egg-info/dependency_links.txt\n",
            "writing entry points to parlai.egg-info/entry_points.txt\n",
            "writing requirements to parlai.egg-info/requires.txt\n",
            "writing top-level names to parlai.egg-info/top_level.txt\n",
            "writing manifest file 'parlai.egg-info/SOURCES.txt'\n",
            "reading manifest file 'parlai.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'parlai.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.10/dist-packages/parlai.egg-link (link to .)\n",
            "Adding parlai 1.7.2 to easy-install.pth file\n",
            "Installing parlai script to /usr/local/bin\n",
            "\n",
            "Installed /content/ParlAI\n",
            "Processing dependencies for parlai==1.7.2\n",
            "Searching for litellm>=0.1.400\n",
            "Reading https://pypi.org/simple/litellm/\n",
            "Downloading https://files.pythonhosted.org/packages/49/42/d16898aa69eade97ac8e8b5ab87d1fae6ee15af61054fcbd750340a785fa/litellm-1.12.9-py3-none-any.whl#sha256=9313d36ef68f99382f1dcbbf2d676d3c9b08a5755cb4f9fbb594bee1f18a6d17\n",
            "Best match: litellm 1.12.9\n",
            "Processing litellm-1.12.9-py3-none-any.whl\n",
            "Installing litellm-1.12.9-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding litellm 1.12.9 to easy-install.pth file\n",
            "Installing litellm script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/litellm-1.12.9-py3.10.egg\n",
            "Searching for openai<=0.27.7\n",
            "Reading https://pypi.org/simple/openai/\n",
            "Downloading https://files.pythonhosted.org/packages/35/c3/de7124146c3edbe8fd8163028d9ac998f2fd5dcda9225655f1d4ed684bbc/openai-0.27.7-py3-none-any.whl#sha256=788fb7fa85bf7caac6c1ed7eea5984254a1bdaf09ef485acf0e5718c8b2dc25a\n",
            "Best match: openai 0.27.7\n",
            "Processing openai-0.27.7-py3-none-any.whl\n",
            "Installing openai-0.27.7-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding openai 0.27.7 to easy-install.pth file\n",
            "Installing openai script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/openai-0.27.7-py3.10.egg\n",
            "Searching for google-api-core<=2.11.0\n",
            "Reading https://pypi.org/simple/google-api-core/\n",
            "Downloading https://files.pythonhosted.org/packages/f7/24/a17e75c733609dce285a2dae6f56837d69a9566963c9d1cab96d788546c8/google_api_core-2.11.0-py3-none-any.whl#sha256=ce222e27b0de0d7bc63eb043b956996d6dccab14cc3b690aaea91c9cc99dc16e\n",
            "Best match: google-api-core 2.11.0\n",
            "Processing google_api_core-2.11.0-py3-none-any.whl\n",
            "Installing google_api_core-2.11.0-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding google-api-core 2.11.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/google_api_core-2.11.0-py3.10.egg\n",
            "Searching for fsspec~=2022.2.0\n",
            "Reading https://pypi.org/simple/fsspec/\n",
            "Downloading https://files.pythonhosted.org/packages/b4/80/cd21f093faef23c03b9fc1274be7a3bfd63b809d2f06a1cff92e00cacfcc/fsspec-2022.2.0-py3-none-any.whl#sha256=eb9c9d9aee49d23028deefffe53e87c55d3515512c63f57e893710301001449a\n",
            "Best match: fsspec 2022.2.0\n",
            "Processing fsspec-2022.2.0-py3-none-any.whl\n",
            "Installing fsspec-2022.2.0-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding fsspec 2022.2.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/fsspec-2022.2.0-py3.10.egg\n",
            "Searching for contractions~=0.1.72\n",
            "Reading https://pypi.org/simple/contractions/\n",
            "Downloading https://files.pythonhosted.org/packages/bb/e4/725241b788963b460ce0118bfd5c505dd3d1bdd020ee740f9f39044ed4a7/contractions-0.1.73-py2.py3-none-any.whl#sha256=398cee3b69c37307a50dce4930d961a0f42b48fdae9562df73bed5683008d3bc\n",
            "Best match: contractions 0.1.73\n",
            "Processing contractions-0.1.73-py2.py3-none-any.whl\n",
            "Installing contractions-0.1.73-py2.py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding contractions 0.1.73 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/contractions-0.1.73-py3.10.egg\n",
            "Searching for ninja~=1.10.2.3\n",
            "Reading https://pypi.org/simple/ninja/\n",
            "Downloading https://files.pythonhosted.org/packages/48/d2/5c106c854b0f2366679747b2a9c5377cc59e03e2b80d72e41588d143abbc/ninja-1.10.2.4-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl#sha256=327c319176c5a4af21908b727b776e9f5caf275680403da632821ba071fd6296\n",
            "Best match: ninja 1.10.2.4\n",
            "Processing ninja-1.10.2.4-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl\n",
            "Installing ninja-1.10.2.4-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding ninja 1.10.2.4 to easy-install.pth file\n",
            "Installing ninja script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/ninja-1.10.2.4-py3.10-linux-x86_64.egg\n",
            "Searching for markdown<=3.3.2\n",
            "Reading https://pypi.org/simple/markdown/\n",
            "Downloading https://files.pythonhosted.org/packages/a0/34/4d6b7e3044044e89eaa25ed5395656cc351163c625fda0656d2729de399f/Markdown-3.3.2-py3-none-any.whl#sha256=77b7bff443b1f97b4814fa438c181fd5882e31edb01b422856b3feca91475f3e\n",
            "Best match: Markdown 3.3.2\n",
            "Processing Markdown-3.3.2-py3-none-any.whl\n",
            "Installing Markdown-3.3.2-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding Markdown 3.3.2 to easy-install.pth file\n",
            "Installing markdown_py script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/Markdown-3.3.2-py3.10.egg\n",
            "Searching for jsonlines\n",
            "Reading https://pypi.org/simple/jsonlines/\n",
            "Downloading https://files.pythonhosted.org/packages/f8/62/d9ba6323b9202dd2fe166beab8a86d29465c41a0288cbe229fac60c1ab8d/jsonlines-4.0.0-py3-none-any.whl#sha256=185b334ff2ca5a91362993f42e83588a360cf95ce4b71a73548502bda52a7c55\n",
            "Best match: jsonlines 4.0.0\n",
            "Processing jsonlines-4.0.0-py3-none-any.whl\n",
            "Installing jsonlines-4.0.0-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding jsonlines 4.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/jsonlines-4.0.0-py3.10.egg\n",
            "Searching for urllib3<1.27,>=1.26.5\n",
            "Reading https://pypi.org/simple/urllib3/\n",
            "Downloading https://files.pythonhosted.org/packages/b0/53/aa91e163dcfd1e5b82d8a890ecf13314e3e149c05270cc644581f77f17fd/urllib3-1.26.18-py2.py3-none-any.whl#sha256=34b97092d7e0a3a8cf7cd10e386f401b3737364026c45e622aa02903dffe0f07\n",
            "Best match: urllib3 1.26.18\n",
            "Processing urllib3-1.26.18-py2.py3-none-any.whl\n",
            "Installing urllib3-1.26.18-py2.py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding urllib3 1.26.18 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/urllib3-1.26.18-py3.10.egg\n",
            "Searching for Unidecode\n",
            "Reading https://pypi.org/simple/Unidecode/\n",
            "Downloading https://files.pythonhosted.org/packages/e4/63/7685ef40c65aba621ccd2524a24181bf11f0535ab1fdba47e40738eacff6/Unidecode-1.3.7-py3-none-any.whl#sha256=663a537f506834ed836af26a81b210d90cbde044c47bfbdc0fbbc9f94c86a6e4\n",
            "Best match: Unidecode 1.3.7\n",
            "Processing Unidecode-1.3.7-py3-none-any.whl\n",
            "Installing Unidecode-1.3.7-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding Unidecode 1.3.7 to easy-install.pth file\n",
            "Installing unidecode script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/Unidecode-1.3.7-py3.10.egg\n",
            "Searching for tqdm~=4.62.1\n",
            "Reading https://pypi.org/simple/tqdm/\n",
            "Downloading https://files.pythonhosted.org/packages/63/f3/b7a1b8e40fd1bd049a34566eb353527bb9b8e9b98f8b6cf803bb64d8ce95/tqdm-4.62.3-py2.py3-none-any.whl#sha256=8dd278a422499cd6b727e6ae4061c40b48fce8b76d1ccbf5d34fca9b7f925b0c\n",
            "Best match: tqdm 4.62.3\n",
            "Processing tqdm-4.62.3-py2.py3-none-any.whl\n",
            "Installing tqdm-4.62.3-py2.py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding tqdm 4.62.3 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/tqdm-4.62.3-py3.10.egg\n",
            "Searching for tensorboardX<=2.5.0\n",
            "Reading https://pypi.org/simple/tensorboardX/\n",
            "Downloading https://files.pythonhosted.org/packages/8b/6e/1a997fbf7f10aa80ea7c70d44c69724bf9dd6823a5d60f6cb6a4a246114e/tensorboardX-2.5-py2.py3-none-any.whl#sha256=b1d8903f8106e2f4484640a293f9680f9757d5f7d2e699e0672bb2382d988e07\n",
            "Best match: tensorboardX 2.5\n",
            "Processing tensorboardX-2.5-py2.py3-none-any.whl\n",
            "Installing tensorboardX-2.5-py2.py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding tensorboardX 2.5 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/tensorboardX-2.5-py3.10.egg\n",
            "Searching for subword-nmt\n",
            "Reading https://pypi.org/simple/subword-nmt/\n",
            "Downloading https://files.pythonhosted.org/packages/1b/9a/488ecac22d78eb429928b9ee4f6b6c692e116ca4bd43ef42a475698def32/subword_nmt-0.3.8-py3-none-any.whl#sha256=d22526b557752f35ac15e8ea384ea7773e50a51d966b8752d023d16cb87eac36\n",
            "Best match: subword-nmt 0.3.8\n",
            "Processing subword_nmt-0.3.8-py3-none-any.whl\n",
            "Installing subword_nmt-0.3.8-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding subword-nmt 0.3.8 to easy-install.pth file\n",
            "Installing subword-nmt script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/subword_nmt-0.3.8-py3.10.egg\n",
            "Searching for Sphinx~=5.1.0\n",
            "Reading https://pypi.org/simple/Sphinx/\n",
            "Downloading https://files.pythonhosted.org/packages/83/74/318d8cd70cbde2164e3035f9e9ba0807e2de7d384e03784ad0afc98b891b/Sphinx-5.1.1-py3-none-any.whl#sha256=309a8da80cb6da9f4713438e5b55861877d5d7976b69d87e336733637ea12693\n",
            "Best match: Sphinx 5.1.1\n",
            "Processing Sphinx-5.1.1-py3-none-any.whl\n",
            "Installing Sphinx-5.1.1-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding Sphinx 5.1.1 to easy-install.pth file\n",
            "Installing sphinx-apidoc script to /usr/local/bin\n",
            "Installing sphinx-autogen script to /usr/local/bin\n",
            "Installing sphinx-build script to /usr/local/bin\n",
            "Installing sphinx-quickstart script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/Sphinx-5.1.1-py3.10.egg\n",
            "Searching for sphinx-autodoc-typehints~=1.10.3\n",
            "Reading https://pypi.org/simple/sphinx-autodoc-typehints/\n",
            "Downloading https://files.pythonhosted.org/packages/00/83/87b8890a93b3994b49960716009c1effb6f7a1fef3a1ec553fda2a7c84de/sphinx_autodoc_typehints-1.10.3-py3-none-any.whl#sha256=27c9e6ef4f4451766ab8d08b2d8520933b97beb21c913f3df9ab2e59b56e6c6c\n",
            "Best match: sphinx-autodoc-typehints 1.10.3\n",
            "Processing sphinx_autodoc_typehints-1.10.3-py3-none-any.whl\n",
            "Installing sphinx_autodoc_typehints-1.10.3-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding sphinx-autodoc-typehints 1.10.3 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/sphinx_autodoc_typehints-1.10.3-py3.10.egg\n",
            "Searching for sphinx_rtd_theme\n",
            "Reading https://pypi.org/simple/sphinx_rtd_theme/\n",
            "Downloading https://files.pythonhosted.org/packages/ea/46/00fda84467815c29951a9c91e3ae7503c409ddad04373e7cfc78daad4300/sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl#sha256=ec93d0856dc280cf3aee9a4c9807c60e027c7f7b461b77aeffed682e68f0e586\n",
            "Best match: sphinx-rtd-theme 2.0.0\n",
            "Processing sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl\n",
            "Installing sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding sphinx-rtd-theme 2.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/sphinx_rtd_theme-2.0.0-py3.10.egg\n",
            "Searching for sh\n",
            "Reading https://pypi.org/simple/sh/\n",
            "Downloading https://files.pythonhosted.org/packages/53/08/9de3e477ad2fd432e78ce351341686d1bbec346976b22c7cc5f81f1ff15a/sh-2.0.6-py3-none-any.whl#sha256=ced8f2e081a858b66a46ace3703dec243779abbd5a1887ba7e3c34f34da70cd2\n",
            "Best match: sh 2.0.6\n",
            "Processing sh-2.0.6-py3-none-any.whl\n",
            "Installing sh-2.0.6-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding sh 2.0.6 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/sh-2.0.6-py3.10.egg\n",
            "Searching for requests-mock\n",
            "Reading https://pypi.org/simple/requests-mock/\n",
            "Downloading https://files.pythonhosted.org/packages/29/e8/ce73e8d1c7ec127cb3af61df3fd04df9a34eef34e511dc03c069748f773d/requests_mock-1.11.0-py2.py3-none-any.whl#sha256=f7fae383f228633f6bececebdab236c478ace2284d6292c6e7e2867b9ab74d15\n",
            "Best match: requests-mock 1.11.0\n",
            "Processing requests_mock-1.11.0-py2.py3-none-any.whl\n",
            "Installing requests_mock-1.11.0-py2.py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding requests-mock 1.11.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/requests_mock-1.11.0-py3.10.egg\n",
            "Searching for attrs~=20.2.0\n",
            "Reading https://pypi.org/simple/attrs/\n",
            "Downloading https://files.pythonhosted.org/packages/14/df/479736ae1ef59842f512548bacefad1abed705e400212acba43f9b0fa556/attrs-20.2.0-py2.py3-none-any.whl#sha256=fce7fc47dfc976152e82d53ff92fa0407700c21acd20886a13777a0d20e655dc\n",
            "Best match: attrs 20.2.0\n",
            "Processing attrs-20.2.0-py2.py3-none-any.whl\n",
            "Installing attrs-20.2.0-py2.py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding attrs 20.2.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/attrs-20.2.0-py3.10.egg\n",
            "Searching for myst-parser<1\n",
            "Reading https://pypi.org/simple/myst-parser/\n",
            "Downloading https://files.pythonhosted.org/packages/6b/2f/bba657533726bdfc341ea997f5b4ab7ed6ab7d6c00bb351a35145b5d320f/myst_parser-0.19.2-py3-none-any.whl#sha256=593afb8fa5566406f7ebd37a6167195f17327ee165398fa9806747e6f68a2729\n",
            "Best match: myst-parser 0.19.2\n",
            "Processing myst_parser-0.19.2-py3-none-any.whl\n",
            "Installing myst_parser-0.19.2-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding myst-parser 0.19.2 to easy-install.pth file\n",
            "Installing myst-anchors script to /usr/local/bin\n",
            "Installing myst-docutils-demo script to /usr/local/bin\n",
            "Installing myst-docutils-html script to /usr/local/bin\n",
            "Installing myst-docutils-html5 script to /usr/local/bin\n",
            "Installing myst-docutils-latex script to /usr/local/bin\n",
            "Installing myst-docutils-pseudoxml script to /usr/local/bin\n",
            "Installing myst-docutils-xml script to /usr/local/bin\n",
            "Installing myst-inv script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/myst_parser-0.19.2-py3.10.egg\n",
            "Searching for py-rouge\n",
            "Reading https://pypi.org/simple/py-rouge/\n",
            "Downloading https://files.pythonhosted.org/packages/9c/1d/0bdbaf559fb7afe32308ebc84a2028600988212d7eb7fb9f69c4e829e4a0/py_rouge-1.1-py3-none-any.whl#sha256=9ae2a859a9edc6d25f3908e48706f7d82d6e78ea18954560c4cb21897dc1d270\n",
            "Best match: py-rouge 1.1\n",
            "Processing py_rouge-1.1-py3-none-any.whl\n",
            "Installing py_rouge-1.1-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding py-rouge 1.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/py_rouge-1.1-py3.10.egg\n",
            "Searching for py-gfm\n",
            "Reading https://pypi.org/simple/py-gfm/\n",
            "Downloading https://files.pythonhosted.org/packages/2d/3b/6d8adfd7ffbddcebea22cebd40679fee0332dbc85ec95e6179fefbaedfdd/py_gfm-2.0.0-py2.py3-none-any.whl#sha256=c49f43b584e15bdbe569141c92aefc00542289b6d88d95b38117e3359a35cdfe\n",
            "Best match: py-gfm 2.0.0\n",
            "Processing py_gfm-2.0.0-py2.py3-none-any.whl\n",
            "Installing py_gfm-2.0.0-py2.py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding py-gfm 2.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/py_gfm-2.0.0-py3.10.egg\n",
            "Searching for pytest_regressions\n",
            "Reading https://pypi.org/simple/pytest_regressions/\n",
            "Downloading https://files.pythonhosted.org/packages/0c/93/086651842707118284e93387355efc5cbbce28bace9265b450d67be55fd8/pytest_regressions-2.5.0-py3-none-any.whl#sha256=8c4e5c4037325fdb0825bc1fdcb75e17e03adf3407049f0cb704bb996d496255\n",
            "Best match: pytest-regressions 2.5.0\n",
            "Processing pytest_regressions-2.5.0-py3-none-any.whl\n",
            "Installing pytest_regressions-2.5.0-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding pytest-regressions 2.5.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/pytest_regressions-2.5.0-py3.10.egg\n",
            "Searching for omegaconf>=2.1.1\n",
            "Reading https://pypi.org/simple/omegaconf/\n",
            "Downloading https://files.pythonhosted.org/packages/67/d4/f0117bc2d36185e0b90c39755259dcdfb86e0f362a9c9db46193501f7c9e/omegaconf-2.4.0.dev1-py3-none-any.whl#sha256=6c202560ac43d3a5aa5aa52d0d5911ea86dc35e56ab02d9e1675f11c7984e729\n",
            "Best match: omegaconf 2.4.0.dev1\n",
            "Processing omegaconf-2.4.0.dev1-py3-none-any.whl\n",
            "Installing omegaconf-2.4.0.dev1-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding omegaconf 2.4.0.dev1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/omegaconf-2.4.0.dev1-py3.10.egg\n",
            "Searching for hydra-core>=1.1.0\n",
            "Reading https://pypi.org/simple/hydra-core/\n",
            "Downloading https://files.pythonhosted.org/packages/c6/50/e0edd38dcd63fb26a8547f13d28f7a008bc4a3fd4eb4ff030673f22ad41a/hydra_core-1.3.2-py3-none-any.whl#sha256=fa0238a9e31df3373b35b0bfb672c34cc92718d21f81311d8996a16de1141d8b\n",
            "Best match: hydra-core 1.3.2\n",
            "Processing hydra_core-1.3.2-py3-none-any.whl\n",
            "Installing hydra_core-1.3.2-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding hydra-core 1.3.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/hydra_core-1.3.2-py3.10.egg\n",
            "Searching for GitPython\n",
            "Reading https://pypi.org/simple/GitPython/\n",
            "Downloading https://files.pythonhosted.org/packages/8d/c4/82b858fb6483dfb5e338123c154d19c043305b01726a67d89532b8f8f01b/GitPython-3.1.40-py3-none-any.whl#sha256=cf14627d5a8049ffbf49915732e5eddbe8134c3bdb9d476e6182b676fc573f8a\n",
            "Best match: GitPython 3.1.40\n",
            "Processing GitPython-3.1.40-py3-none-any.whl\n",
            "Installing GitPython-3.1.40-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding GitPython 3.1.40 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/GitPython-3.1.40-py3.10.egg\n",
            "Searching for gitdb2\n",
            "Reading https://pypi.org/simple/gitdb2/\n",
            "Downloading https://files.pythonhosted.org/packages/52/7e/59f96b47f671b3fe0aa0c1b609531a540434b719a10c417581e25b383909/gitdb2-4.0.2-py3-none-any.whl#sha256=a1c974e5fab8c2c90192c1367c81cbc54baec04244bda1816e9c8ab377d1cba3\n",
            "Best match: gitdb2 4.0.2\n",
            "Processing gitdb2-4.0.2-py3-none-any.whl\n",
            "Installing gitdb2-4.0.2-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding gitdb2 4.0.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/gitdb2-4.0.2-py3.10.egg\n",
            "Searching for iopath~=0.1.8\n",
            "Reading https://pypi.org/simple/iopath/\n",
            "Downloading https://files.pythonhosted.org/packages/72/73/b3d451dfc523756cf177d3ebb0af76dc7751b341c60e2a21871be400ae29/iopath-0.1.10.tar.gz#sha256=3311c16a4d9137223e20f141655759933e1eda24f8bff166af834af3c645ef01\n",
            "Best match: iopath 0.1.10\n",
            "Processing iopath-0.1.10.tar.gz\n",
            "Writing /tmp/easy_install-5nyjkxd2/iopath-0.1.10/setup.cfg\n",
            "Running iopath-0.1.10/setup.py -q bdist_egg --dist-dir /tmp/easy_install-5nyjkxd2/iopath-0.1.10/egg-dist-tmp-ky8i92yq\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Adding iopath 0.1.10 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/iopath-0.1.10-py3.10.egg\n",
            "Searching for fuzzywuzzy\n",
            "Reading https://pypi.org/simple/fuzzywuzzy/\n",
            "Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl#sha256=928244b28db720d1e0ee7587acf660ea49d7e4c632569cad4f1cd7e68a5f0993\n",
            "Best match: fuzzywuzzy 0.18.0\n",
            "Processing fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
            "Installing fuzzywuzzy-0.18.0-py2.py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding fuzzywuzzy 0.18.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/fuzzywuzzy-0.18.0-py3.10.egg\n",
            "Searching for flake8\n",
            "Reading https://pypi.org/simple/flake8/\n",
            "Downloading https://files.pythonhosted.org/packages/b0/24/bbf7175ffc47cb3d3e1eb523ddb23272968359dfcf2e1294707a2bf12fc4/flake8-6.1.0-py2.py3-none-any.whl#sha256=ffdfce58ea94c6580c77888a86506937f9a1a227dfcd15f245d694ae20a6b6e5\n",
            "Best match: flake8 6.1.0\n",
            "Processing flake8-6.1.0-py2.py3-none-any.whl\n",
            "Installing flake8-6.1.0-py2.py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding flake8 6.1.0 to easy-install.pth file\n",
            "Installing flake8 script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/flake8-6.1.0-py3.10.egg\n",
            "Searching for flake8-bugbear\n",
            "Reading https://pypi.org/simple/flake8-bugbear/\n",
            "Downloading https://files.pythonhosted.org/packages/02/77/087de3a265b00d3197ffc90424da6c22180a24578460ee43cc8b97556bc0/flake8_bugbear-23.12.2-py3-none-any.whl#sha256=83324bad4d90fee4bf64dd69c61aff94debf8073fbd807c8b6a36eec7a2f0719\n",
            "Best match: flake8-bugbear 23.12.2\n",
            "Processing flake8_bugbear-23.12.2-py3-none-any.whl\n",
            "Installing flake8_bugbear-23.12.2-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding flake8-bugbear 23.12.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/flake8_bugbear-23.12.2-py3.10.egg\n",
            "Searching for docformatter~=1.4.0\n",
            "Reading https://pypi.org/simple/docformatter/\n",
            "Downloading https://files.pythonhosted.org/packages/8a/7b/b32b3952ee4e9fd76c7a9b18d4bafb70ed65ac6426d1802103c2eaf1d0de/docformatter-1.4.tar.gz#sha256=064e6d81f04ac96bc0d176cbaae953a0332482b22d3ad70d47c8a7f2732eef6f\n",
            "Best match: docformatter 1.4\n",
            "Processing docformatter-1.4.tar.gz\n",
            "Writing /tmp/easy_install-4w31g3py/docformatter-1.4/setup.cfg\n",
            "Running docformatter-1.4/setup.py -q bdist_egg --dist-dir /tmp/easy_install-4w31g3py/docformatter-1.4/egg-dist-tmp-mmttm8uu\n",
            "warning: no previously-included files found matching '.pre-commit-hooks.yaml'\n",
            "warning: no previously-included files found matching '.travis.yml'\n",
            "warning: no previously-included files found matching 'Makefile'\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "Adding docformatter 1.4 to easy-install.pth file\n",
            "Installing docformatter script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/docformatter-1.4-py3.10.egg\n",
            "Searching for fairscale~=0.4.1\n",
            "Reading https://pypi.org/simple/fairscale/\n",
            "Downloading https://files.pythonhosted.org/packages/c1/08/b3334d7b543ac10dcb129cef4f84723ab696725512f18d69ab3a784b0bf5/fairscale-0.4.13.tar.gz#sha256=1b797825c427f5dba92253fd0d8daa574e8bd651a2423497775fab1b30cfb768\n",
            "Best match: fairscale 0.4.13\n",
            "Processing fairscale-0.4.13.tar.gz\n",
            "Writing /tmp/easy_install-28o0gs1w/fairscale-0.4.13/setup.cfg\n",
            "Running fairscale-0.4.13/setup.py -q bdist_egg --dist-dir /tmp/easy_install-28o0gs1w/fairscale-0.4.13/egg-dist-tmp-q5asvods\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py:84: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Requirements should be satisfied by a PEP 517 installer.\n",
            "        If you are using pip, you can try `pip install --use-pep517`.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  dist.fetch_build_eggs(dist.setup_requires)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/command/build_py.py:201: _Warning: Package 'fairscale.clib.fused_adam_cuda' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'fairscale.clib.fused_adam_cuda' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'fairscale.clib.fused_adam_cuda' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'fairscale.clib.fused_adam_cuda' to be distributed and are\n",
            "        already explicitly excluding 'fairscale.clib.fused_adam_cuda' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "fairscale.experimental.nn.distributed_pipeline.__pycache__.trace.cpython-310: module MAY be using inspect.trace\n",
            "Adding fairscale 0.4.13 to easy-install.pth file\n",
            "Installing wgit script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/fairscale-0.4.13-py3.10.egg\n",
            "Searching for emoji\n",
            "Reading https://pypi.org/simple/emoji/\n",
            "Downloading https://files.pythonhosted.org/packages/03/40/91d0c9fe5a0b494c0fdbcacda4d203aea39f8293e69c70129389308ca928/emoji-2.9.0-py2.py3-none-any.whl#sha256=17b0d53e1d9f787307a4c65aa19badb0a1ffdbc89b3a3cd851fc77821cdaced2\n",
            "Best match: emoji 2.9.0\n",
            "Processing emoji-2.9.0-py2.py3-none-any.whl\n",
            "Installing emoji-2.9.0-py2.py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding emoji 2.9.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/emoji-2.9.0-py3.10.egg\n",
            "Searching for docutils<0.16,>=0.14\n",
            "Reading https://pypi.org/simple/docutils/\n",
            "Downloading https://files.pythonhosted.org/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl#sha256=6c4f696463b79f1fb8ba0c594b63840ebd41f059e92b31957c46b74a4599b6d0\n",
            "Best match: docutils 0.15.2\n",
            "Processing docutils-0.15.2-py3-none-any.whl\n",
            "Installing docutils-0.15.2-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding docutils 0.15.2 to easy-install.pth file\n",
            "Installing rst2xml.py script to /usr/local/bin\n",
            "Installing rst2pseudoxml.py script to /usr/local/bin\n",
            "Installing rst2html4.py script to /usr/local/bin\n",
            "Installing rst2latex.py script to /usr/local/bin\n",
            "Installing rstpep2html.py script to /usr/local/bin\n",
            "Installing rst2xetex.py script to /usr/local/bin\n",
            "Installing rst2html5.py script to /usr/local/bin\n",
            "Installing rst2html.py script to /usr/local/bin\n",
            "Installing rst2odt.py script to /usr/local/bin\n",
            "Installing rst2man.py script to /usr/local/bin\n",
            "Installing rst2odt_prepstyles.py script to /usr/local/bin\n",
            "Installing rst2s5.py script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/docutils-0.15.2-py3.10.egg\n",
            "Searching for datasets<2.2.2,>=1.4.1\n",
            "Reading https://pypi.org/simple/datasets/\n",
            "Downloading https://files.pythonhosted.org/packages/d7/2d/41e8aec8d4bad6f07adfcbc89cf743e0d31c876371d453b2936bcfa7fe34/datasets-2.2.1-py3-none-any.whl#sha256=1938f3e99599422de50b9b54fe802aca854ed130382dab0b3820c821f7ae6d5e\n",
            "Best match: datasets 2.2.1\n",
            "Processing datasets-2.2.1-py3-none-any.whl\n",
            "Installing datasets-2.2.1-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding datasets 2.2.1 to easy-install.pth file\n",
            "Installing datasets-cli script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/datasets-2.2.1-py3.10.egg\n",
            "Searching for coloredlogs\n",
            "Reading https://pypi.org/simple/coloredlogs/\n",
            "Downloading https://files.pythonhosted.org/packages/a7/06/3d6badcf13db419e25b07041d9c7b4a2c331d3f4e7134445ec5df57714cd/coloredlogs-15.0.1-py2.py3-none-any.whl#sha256=612ee75c546f53e92e70049c9dbfcc18c935a2b9a53b66085ce9ef6a6e5c0934\n",
            "Best match: coloredlogs 15.0.1\n",
            "Processing coloredlogs-15.0.1-py2.py3-none-any.whl\n",
            "Installing coloredlogs-15.0.1-py2.py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding coloredlogs 15.0.1 to easy-install.pth file\n",
            "Installing coloredlogs script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/coloredlogs-15.0.1-py3.10.egg\n",
            "Searching for tiktoken>=0.4.0\n",
            "Reading https://pypi.org/simple/tiktoken/\n",
            "Downloading https://files.pythonhosted.org/packages/bf/56/a8910841d1f501cf8affeb06a0335a518888505c60ec9f2a2a6393190e48/tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=72ad8ae2a747622efae75837abba59be6c15a8f31b4ac3c6156bc56ec7a8e631\n",
            "Best match: tiktoken 0.5.2\n",
            "Processing tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
            "Installing tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding tiktoken 0.5.2 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/tiktoken-0.5.2-py3.10-linux-x86_64.egg\n",
            "Searching for python-dotenv>=0.2.0\n",
            "Reading https://pypi.org/simple/python-dotenv/\n",
            "Downloading https://files.pythonhosted.org/packages/44/2f/62ea1c8b593f4e093cc1a7768f0d46112107e790c3e478532329e434f00b/python_dotenv-1.0.0-py3-none-any.whl#sha256=f5971a9226b701070a4bf2c38c89e5a3f0d64de8debda981d1db98583009122a\n",
            "Best match: python-dotenv 1.0.0\n",
            "Processing python_dotenv-1.0.0-py3-none-any.whl\n",
            "Installing python_dotenv-1.0.0-py3-none-any.whl to /usr/local/lib/python3.10/dist-packages\n",
            "Adding python-dotenv 1.0.0 to easy-install.pth file\n",
            "Installing dotenv script to /usr/local/bin\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/python_dotenv-1.0.0-py3.10.egg\n",
            "error: openai 0.27.7 is installed but openai>=1.0.0 is required by {'litellm'}\n"
          ]
        }
      ],
      "source": [
        "!python setup.py develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5Jce4NXImzz",
        "outputId": "87f9e61e-764c-4fa0-dcb7-207e2c680051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.10/dist-packages/iopath-0.1.10-py3.10.egg (0.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from iopath) (4.66.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath) (4.5.0)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install portalocker iopath"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install NVIDIA Apex"
      ],
      "metadata": {
        "id": "in_yZ13jhB_e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKpbVCWxMXGX",
        "outputId": "e2d23fac-2e35-414a-ca48-8c41db11de2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 11521, done.\u001b[K\n",
            "remote: Counting objects: 100% (3589/3589), done.\u001b[K\n",
            "remote: Compressing objects: 100% (506/506), done.\u001b[K\n",
            "remote: Total 11521 (delta 3265), reused 3181 (delta 3080), pack-reused 7932\u001b[K\n",
            "Receiving objects: 100% (11521/11521), 15.43 MiB | 19.82 MiB/s, done.\n",
            "Resolving deltas: 100% (8094/8094), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVIDIA/apex"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLiIbXOAfCE8",
        "outputId": "49bb8844-d84f-46c8-cb57-eca6ff7b22e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ParlAI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAEsuTprMZ1f",
        "outputId": "05ca7053-8e57-4056-d556-39a6381a5f7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ParlAI/apex\n"
          ]
        }
      ],
      "source": [
        "cd /content/ParlAI/apex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H19t_hDEOkQQ",
        "outputId": "adc541c2-972d-48e8-c9b0-61b4be669b5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cuda-python\n",
            "  Downloading cuda_python-12.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cuda-python\n",
            "Successfully installed cuda-python-12.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install cuda-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YPOzm48PDC3",
        "outputId": "be7e60c2-44a3-4d42-cc0a-d887902afa79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "torch.__version__  = 2.1.0+cu118\n",
            "\n",
            "\n",
            "running develop\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "creating apex.egg-info\n",
            "writing apex.egg-info/PKG-INFO\n",
            "writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "writing requirements to apex.egg-info/requires.txt\n",
            "writing top-level names to apex.egg-info/top_level.txt\n",
            "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "reading manifest file 'apex.egg-info/SOURCES.txt'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "Creating /usr/local/lib/python3.10/dist-packages/apex.egg-link (link to .)\n",
            "Adding apex 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /content/ParlAI/apex\n",
            "Processing dependencies for apex==0.1\n",
            "Searching for packaging==23.2\n",
            "Best match: packaging 23.2\n",
            "Adding packaging 23.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.10/dist-packages\n",
            "Finished processing dependencies for apex==0.1\n"
          ]
        }
      ],
      "source": [
        "!python setup.py develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZR-EB0fE9Nq",
        "outputId": "4509876b-e1c6-4456-d92f-70994933c86d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n"
          ]
        }
      ],
      "source": [
        "cd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SXZCjiCqPdhr",
        "outputId": "118fb820-fca1-4512-f3ad-39c89d4bb262"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zYGoogCMhOO",
        "outputId": "b013c93a-b526-4b9a-ebf6-2240cba148b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mDEPRECATION: --build-option and --global-option are deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use --config-settings. Discussion can be found at https://github.com/pypa/pip/issues/11859\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Implying --no-binary=:all: due to the presence of --build-option / --global-option. \u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: apex in /content/ParlAI/apex (0.1)\n",
            "Requirement already satisfied: packaging>20.6 in /usr/local/lib/python3.10/dist-packages (from apex) (23.2)\n"
          ]
        }
      ],
      "source": [
        "!cd /content/ParlAI/apex/apex\n",
        "#!cd /content/ParlAI/apex/apex\n",
        "!pip install apex --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp7ZD1QBEsjc",
        "outputId": "eed21756-b134-4870-aac8-ffd5077d34b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 2.0.0+cu118\n",
            "Uninstalling torch-2.0.0+cu118:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/bin/torchrun\n",
            "    /usr/local/lib/python3.9/dist-packages/functorch/*\n",
            "    /usr/local/lib/python3.9/dist-packages/nvfuser/*\n",
            "    /usr/local/lib/python3.9/dist-packages/torch-2.0.0+cu118.dist-info/*\n",
            "    /usr/local/lib/python3.9/dist-packages/torch/*\n",
            "    /usr/local/lib/python3.9/dist-packages/torchgen/*\n",
            "Proceed (Y/n)? y\n",
            "y\n"
          ]
        }
      ],
      "source": [
        "!pip3 uninstall torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z6_Ht57M7hx",
        "outputId": "99dffcb1-77e9-4d04-8c76-e8ac7944db1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.8.1+cu111 (from versions: 1.11.0, 1.11.0+cpu, 1.11.0+cu102, 1.11.0+cu113, 1.11.0+cu115, 1.11.0+rocm4.3.1, 1.11.0+rocm4.5.2, 1.12.0, 1.12.0+cpu, 1.12.0+cu102, 1.12.0+cu113, 1.12.0+cu116, 1.12.0+rocm5.0, 1.12.0+rocm5.1.1, 1.12.1, 1.12.1+cpu, 1.12.1+cu102, 1.12.1+cu113, 1.12.1+cu116, 1.12.1+rocm5.0, 1.12.1+rocm5.1.1, 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.0+cu117.with.pypi.cudnn, 1.13.0+rocm5.1.1, 1.13.0+rocm5.2, 1.13.1, 1.13.1+cpu, 1.13.1+cu116, 1.13.1+cu117, 1.13.1+cu117.with.pypi.cudnn, 1.13.1+rocm5.1.1, 1.13.1+rocm5.2, 2.0.0, 2.0.0+cpu, 2.0.0+cpu.cxx11.abi, 2.0.0+cu117, 2.0.0+cu117.with.pypi.cudnn, 2.0.0+cu118, 2.0.0+rocm5.3, 2.0.0+rocm5.4.2, 2.0.1, 2.0.1+cpu, 2.0.1+cpu.cxx11.abi, 2.0.1+cu117, 2.0.1+cu117.with.pypi.cudnn, 2.0.1+cu118, 2.0.1+rocm5.3, 2.0.1+rocm5.4.2, 2.1.0, 2.1.0+cpu, 2.1.0+cpu.cxx11.abi, 2.1.0+cu118, 2.1.0+cu121, 2.1.0+cu121.with.pypi.cudnn, 2.1.0+rocm5.5, 2.1.0+rocm5.6)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.8.1+cu111\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLn7PltqL8yy",
        "outputId": "03b8f2ab-c9ef-4d8d-b09f-ab474acf17ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.8/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: apex 0.9.10.dev0\n",
            "Uninstalling apex-0.9.10.dev0:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.8/dist-packages/apex-0.9.10.dev0.dist-info/*\n",
            "    /usr/local/lib/python3.8/dist-packages/apex/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled apex-0.9.10.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall apex"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2X4qulqNDXH",
        "outputId": "2cf60248-8a5b-4b84-97a8-56014323ec0f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install parlai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O41G7K8MtWoI",
        "outputId": "6d3661dd-86e3-4293-83c0-9d77ad93f138"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: parlai in /content/ParlAI (1.7.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages/coloredlogs-15.0.1-py3.10.egg (from parlai) (15.0.1)\n",
            "Requirement already satisfied: datasets<2.2.2,>=1.4.1 in /usr/local/lib/python3.10/dist-packages/datasets-2.2.1-py3.10.egg (from parlai) (2.2.1)\n",
            "Collecting docutils<0.16,>=0.14 (from parlai)\n",
            "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m547.6/547.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages/emoji-2.9.0-py3.10.egg (from parlai) (2.9.0)\n",
            "Requirement already satisfied: fairscale~=0.4.1 in /usr/local/lib/python3.10/dist-packages/fairscale-0.4.13-py3.10.egg (from parlai) (0.4.13)\n",
            "Requirement already satisfied: docformatter~=1.4.0 in /usr/local/lib/python3.10/dist-packages/docformatter-1.4-py3.10.egg (from parlai) (1.4)\n",
            "Requirement already satisfied: flake8-bugbear in /usr/local/lib/python3.10/dist-packages/flake8_bugbear-23.12.2-py3.10.egg (from parlai) (23.12.2)\n",
            "Requirement already satisfied: flake8 in /usr/local/lib/python3.10/dist-packages/flake8-6.1.0-py3.10.egg (from parlai) (6.1.0)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.10/dist-packages/fuzzywuzzy-0.18.0-py3.10.egg (from parlai) (0.18.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from parlai) (2.8.0)\n",
            "Requirement already satisfied: iopath~=0.1.8 in /usr/local/lib/python3.10/dist-packages/iopath-0.1.10-py3.10.egg (from parlai) (0.1.10)\n",
            "Requirement already satisfied: gitdb2 in /usr/local/lib/python3.10/dist-packages/gitdb2-4.0.2-py3.10.egg (from parlai) (4.0.2)\n",
            "Requirement already satisfied: GitPython in /usr/local/lib/python3.10/dist-packages/GitPython-3.1.40-py3.10.egg (from parlai) (3.1.40)\n",
            "Requirement already satisfied: hydra-core>=1.1.0 in /usr/local/lib/python3.10/dist-packages/hydra_core-1.3.2-py3.10.egg (from parlai) (1.3.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from parlai) (7.34.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from parlai) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from parlai) (0.16.0+cu118)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from parlai) (1.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from parlai) (3.8.1)\n",
            "Requirement already satisfied: omegaconf>=2.1.1 in /usr/local/lib/python3.10/dist-packages/omegaconf-2.4.0.dev1-py3.10.egg (from parlai) (2.4.0.dev1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from parlai) (1.5.3)\n",
            "Requirement already satisfied: pytest_regressions in /usr/local/lib/python3.10/dist-packages/pytest_regressions-2.5.0-py3.10.egg (from parlai) (2.5.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from parlai) (7.4.3)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.10/dist-packages (from parlai) (4.9.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from parlai) (9.4.0)\n",
            "Requirement already satisfied: py-gfm in /usr/local/lib/python3.10/dist-packages/py_gfm-2.0.0-py3.10.egg (from parlai) (2.0.0)\n",
            "Requirement already satisfied: py-rouge in /usr/local/lib/python3.10/dist-packages/py_rouge-1.1-py3.10.egg (from parlai) (1.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from parlai) (6.0.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from parlai) (23.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from parlai) (2023.6.3)\n",
            "Requirement already satisfied: myst-parser<1 in /usr/local/lib/python3.10/dist-packages/myst_parser-0.19.2-py3.10.egg (from parlai) (0.19.2)\n",
            "Collecting attrs~=20.2.0 (from parlai)\n",
            "  Downloading attrs-20.2.0-py2.py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests-mock in /usr/local/lib/python3.10/dist-packages/requests_mock-1.11.0-py3.10.egg (from parlai) (1.11.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from parlai) (2.31.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from parlai) (1.11.4)\n",
            "Requirement already satisfied: sh in /usr/local/lib/python3.10/dist-packages/sh-2.0.6-py3.10.egg (from parlai) (2.0.6)\n",
            "Requirement already satisfied: sphinx_rtd_theme in /usr/local/lib/python3.10/dist-packages/sphinx_rtd_theme-2.0.0-py3.10.egg (from parlai) (2.0.0)\n",
            "Requirement already satisfied: sphinx-autodoc-typehints~=1.10.3 in /usr/local/lib/python3.10/dist-packages/sphinx_autodoc_typehints-1.10.3-py3.10.egg (from parlai) (1.10.3)\n",
            "Collecting Sphinx~=5.1.0 (from parlai)\n",
            "  Downloading Sphinx-5.1.1-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: subword-nmt in /usr/local/lib/python3.10/dist-packages/subword_nmt-0.3.8-py3.10.egg (from parlai) (0.3.8)\n",
            "Requirement already satisfied: tensorboardX<=2.5.0 in /usr/local/lib/python3.10/dist-packages/tensorboardX-2.5-py3.10.egg (from parlai) (2.5)\n",
            "Requirement already satisfied: tokenizers>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from parlai) (0.15.0)\n",
            "Requirement already satisfied: tomli>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from parlai) (2.0.1)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (from parlai) (0.16.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from parlai) (6.3.2)\n",
            "Collecting tqdm~=4.62.1 (from parlai)\n",
            "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from parlai) (4.5.0)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.10/dist-packages/Unidecode-1.3.7-py3.10.egg (from parlai) (1.3.7)\n",
            "Collecting urllib3<1.27,>=1.26.5 (from parlai)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m611.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from parlai) (1.7.0)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages/jsonlines-4.0.0-py3.10.egg (from parlai) (4.0.0)\n",
            "Requirement already satisfied: numpy~=1.23.0 in /usr/local/lib/python3.10/dist-packages (from parlai) (1.23.5)\n",
            "Collecting markdown<=3.3.2 (from parlai)\n",
            "  Downloading Markdown-3.3.2-py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m95.9/95.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from parlai) (3.1.2)\n",
            "Requirement already satisfied: ninja~=1.10.2.3 in /usr/local/lib/python3.10/dist-packages/ninja-1.10.2.4-py3.10-linux-x86_64.egg (from parlai) (1.10.2.4)\n",
            "Requirement already satisfied: protobuf<=3.20.3,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from parlai) (3.20.3)\n",
            "Requirement already satisfied: contractions~=0.1.72 in /usr/local/lib/python3.10/dist-packages/contractions-0.1.73-py3.10.egg (from parlai) (0.1.73)\n",
            "Collecting fsspec~=2022.2.0 (from parlai)\n",
            "  Downloading fsspec-2022.2.0-py3-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-api-core<=2.11.0 (from parlai)\n",
            "  Downloading google_api_core-2.11.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m120.3/120.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openai<=0.27.7 in /usr/local/lib/python3.10/dist-packages/openai-0.27.7-py3.10.egg (from parlai) (0.27.7)\n",
            "Requirement already satisfied: litellm>=0.1.400 in /usr/local/lib/python3.10/dist-packages/litellm-1.12.9-py3.10.egg (from parlai) (1.12.9)\n",
            "Collecting textsearch>=0.0.21 (from contractions~=0.1.72->parlai)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<2.2.2,>=1.4.1->parlai) (10.0.1)\n",
            "Collecting dill (from datasets<2.2.2,>=1.4.1->parlai)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<2.2.2,>=1.4.1->parlai) (3.4.1)\n",
            "Collecting multiprocess (from datasets<2.2.2,>=1.4.1->parlai)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from datasets<2.2.2,>=1.4.1->parlai) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<2.2.2,>=1.4.1->parlai) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<2.2.2,>=1.4.1->parlai) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets<2.2.2,>=1.4.1->parlai) (23.2)\n",
            "Collecting responses<0.19 (from datasets<2.2.2,>=1.4.1->parlai)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting untokenize (from docformatter~=1.4.0->parlai)\n",
            "  Downloading untokenize-0.1.1.tar.gz (3.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<=2.11.0->parlai) (1.61.0)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<=2.11.0->parlai) (2.17.3)\n",
            "Collecting omegaconf>=2.1.1 (from parlai)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1.0->parlai)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath~=0.1.8->parlai) (2.8.2)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from litellm>=0.1.400->parlai) (1.4.4)\n",
            "Requirement already satisfied: certifi<2024.0.0,>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from litellm>=0.1.400->parlai) (2023.11.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from litellm>=0.1.400->parlai) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=0.1.400->parlai) (7.0.0)\n",
            "INFO: pip is looking at multiple versions of litellm to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting litellm>=0.1.400 (from parlai)\n",
            "  Downloading litellm-1.12.8-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.12.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.12.6-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.12.5-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.12.3-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.12.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.12.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of litellm to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading litellm-1.12.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.11.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.11.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.10.11-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.10.10-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading litellm-1.10.9-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.10.8-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.10.6-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.10.4-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.10.3-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.10.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.10.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.10.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.9.5-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.9.4-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.9.3-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.9.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.9.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.9.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.21-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.19-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.18-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.17-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.16-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.14-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.13-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.12-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.11-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.9-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.8-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.6-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.5-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.4-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.3-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.7.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.6.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.4.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.3.3-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.3.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.2.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.1.3-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.1.2-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.1.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.1.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.0.3-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading litellm-1.0.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.10/dist-packages/python_dotenv-1.0.0-py3.10.egg (from litellm>=0.1.400->parlai) (1.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.4.0 in /usr/local/lib/python3.10/dist-packages/tiktoken-0.5.2-py3.10-linux-x86_64.egg (from litellm>=0.1.400->parlai) (0.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->parlai) (2.1.3)\n",
            "Collecting markdown-it-py<3.0.0,>=1.0.0 (from myst-parser<1->parlai)\n",
            "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdit-py-plugins~=0.3.4 (from myst-parser<1->parlai)\n",
            "  Downloading mdit_py_plugins-0.3.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->parlai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->parlai) (3.6)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from Sphinx~=5.1.0->parlai) (1.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from Sphinx~=5.1.0->parlai) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from Sphinx~=5.1.0->parlai) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from Sphinx~=5.1.0->parlai) (2.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from Sphinx~=5.1.0->parlai) (1.1.9)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from Sphinx~=5.1.0->parlai) (1.0.6)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from Sphinx~=5.1.0->parlai) (2.16.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from Sphinx~=5.1.0->parlai) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from Sphinx~=5.1.0->parlai) (2.13.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from Sphinx~=5.1.0->parlai) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from Sphinx~=5.1.0->parlai) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorboardX<=2.5.0->parlai) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->parlai) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->parlai) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->parlai) (3.2.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->parlai) (2.1.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->parlai)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mccabe<0.8.0,>=0.7.0 (from flake8->parlai)\n",
            "  Downloading mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting pycodestyle<2.12.0,>=2.11.0 (from flake8->parlai)\n",
            "  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
            "Collecting pyflakes<3.2.0,>=3.1.0 (from flake8->parlai)\n",
            "  Downloading pyflakes-3.1.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb>=4.0.1 (from gitdb2->parlai)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->parlai) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->parlai) (2.6.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->parlai) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->parlai)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->parlai) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->parlai) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->parlai) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->parlai) (3.0.41)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->parlai) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->parlai) (0.1.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect->parlai) (0.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->parlai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->parlai) (2023.3.post1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->parlai) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->parlai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->parlai) (1.2.0)\n",
            "Collecting pytest-datadir>=1.2.0 (from pytest_regressions->parlai)\n",
            "  Downloading pytest_datadir-1.5.0-py3-none-any.whl (5.1 kB)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx_rtd_theme->parlai)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mock (from subword-nmt->parlai)\n",
            "  Downloading mock-5.1.0-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.10/dist-packages (from torchtext->parlai) (0.7.0)\n",
            "INFO: pip is looking at multiple versions of fsspec[http] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting fsspec[http]>=2021.05.0 (from datasets<2.2.2,>=1.4.1->parlai)\n",
            "  Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.12.1-py3-none-any.whl (168 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m168.9/168.9 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.12.0-py3-none-any.whl (168 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m168.9/168.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.9.1-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m173.4/173.4 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.9.0-py3-none-any.whl (173 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m173.2/173.2 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of fsspec[http] to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m154.0/154.0 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.3.0-py3-none-any.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m145.4/145.4 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m139.5/139.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading fsspec-2022.10.0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m138.8/138.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2022.8.2-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m140.8/140.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m141.2/141.2 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2022.7.0-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m141.2/141.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m136.1/136.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb>=4.0.1->gitdb2->parlai)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<=2.11.0->parlai) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<=2.11.0->parlai) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<=2.11.0->parlai) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage->parlai) (1.5.0)\n",
            "INFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0 (from datasets<2.2.2,>=1.4.1->parlai)\n",
            "  Downloading huggingface_hub-0.19.3-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading huggingface_hub-0.19.2-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading huggingface_hub-0.19.1-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m311.1/311.1 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm>=0.1.400->parlai) (3.17.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->parlai) (0.8.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=1.0.0->myst-parser<1->parlai) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->parlai) (0.2.12)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions~=0.1.72->parlai)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions~=0.1.72->parlai)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<2.2.2,>=1.4.1->parlai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<2.2.2,>=1.4.1->parlai) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<2.2.2,>=1.4.1->parlai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<2.2.2,>=1.4.1->parlai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<2.2.2,>=1.4.1->parlai) (4.0.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->parlai) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core<=2.11.0->parlai) (0.5.1)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, untokenize\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=3df4f70f7d104b3edab77f94a0938c4ae800afaa907268bc5e31ec665305cdc2\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for untokenize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for untokenize: filename=untokenize-0.1.1-py3-none-any.whl size=2875 sha256=06c01555ab12194d695f6fd738ed9d21a8192fc6a31c25a3918b82b764795d25\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/b6/d4/187059c19a28026b81e54afd260a63aab2e7ccddf2e05977eb\n",
            "Successfully built antlr4-python3-runtime untokenize\n",
            "Installing collected packages: untokenize, antlr4-python3-runtime, urllib3, tqdm, smmap, pyflakes, pycodestyle, pyahocorasick, omegaconf, mock, mccabe, markdown-it-py, markdown, jedi, humanfriendly, fsspec, docutils, dill, attrs, anyascii, textsearch, pytest-datadir, multiprocess, mdit-py-plugins, gitdb, responses, huggingface-hub, google-api-core, litellm, Sphinx, sphinxcontrib-jquery\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: omegaconf\n",
            "    Found existing installation: omegaconf 2.4.0.dev1\n",
            "    Uninstalling omegaconf-2.4.0.dev1:\n",
            "      Successfully uninstalled omegaconf-2.4.0.dev1\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.5.1\n",
            "    Uninstalling Markdown-3.5.1:\n",
            "      Successfully uninstalled Markdown-3.5.1\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.6.0\n",
            "    Uninstalling fsspec-2023.6.0:\n",
            "      Successfully uninstalled fsspec-2023.6.0\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.18.1\n",
            "    Uninstalling docutils-0.18.1:\n",
            "      Successfully uninstalled docutils-0.18.1\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 23.1.0\n",
            "    Uninstalling attrs-23.1.0:\n",
            "      Successfully uninstalled attrs-23.1.0\n",
            "  Attempting uninstall: mdit-py-plugins\n",
            "    Found existing installation: mdit-py-plugins 0.4.0\n",
            "    Uninstalling mdit-py-plugins-0.4.0:\n",
            "      Successfully uninstalled mdit-py-plugins-0.4.0\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 2.11.1\n",
            "    Uninstalling google-api-core-2.11.1:\n",
            "      Successfully uninstalled google-api-core-2.11.1\n",
            "  Attempting uninstall: litellm\n",
            "    Found existing installation: litellm 1.12.9\n",
            "    Uninstalling litellm-1.12.9:\n",
            "      Successfully uninstalled litellm-1.12.9\n",
            "  Attempting uninstall: Sphinx\n",
            "    Found existing installation: Sphinx 5.0.2\n",
            "    Uninstalling Sphinx-5.0.2:\n",
            "      Successfully uninstalled Sphinx-5.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "bigframes 0.15.0 requires fsspec>=2023.3.0, but you have fsspec 2022.2.0 which is incompatible.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2022.2.0 which is incompatible.\n",
            "jsonschema 4.19.2 requires attrs>=22.2.0, but you have attrs 20.2.0 which is incompatible.\n",
            "referencing 0.31.1 requires attrs>=22.2.0, but you have attrs 20.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Sphinx-5.1.1 antlr4-python3-runtime-4.9.3 anyascii-0.3.2 attrs-20.2.0 dill-0.3.7 docutils-0.15.2 fsspec-2022.2.0 gitdb-4.0.11 google-api-core-2.11.0 huggingface-hub-0.17.3 humanfriendly-10.0 jedi-0.19.1 litellm-1.0.0 markdown-3.3.2 markdown-it-py-2.2.0 mccabe-0.7.0 mdit-py-plugins-0.3.5 mock-5.1.0 multiprocess-0.70.15 omegaconf-2.3.0 pyahocorasick-2.0.0 pycodestyle-2.11.1 pyflakes-3.1.0 pytest-datadir-1.5.0 responses-0.18.0 smmap-5.0.1 sphinxcontrib-jquery-4.1 textsearch-0.0.24 tqdm-4.62.3 untokenize-0.1.1 urllib3-1.26.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk; nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAWlvf7_UzEO",
        "outputId": "cadc752d-b444-4941-dd73-2acdf7425f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive/parlbb"
      ],
      "metadata": {
        "id": "dCC4_fVDZxVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "/content/ParlAI/data/models/blender/blender_90M/model"
      ],
      "metadata": {
        "id": "Kg2wc6hmIMj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train model"
      ],
      "metadata": {
        "id": "dOCVGV4dhLs_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E5_0GKm6tUX",
        "outputId": "edc4b855-d371-4eb3-f82b-3f39a4f21c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02:56:49 | building dictionary first...\n",
            "02:56:49 | \u001b[33mOverriding opt[\"task\"] to dailydialog (previously: convai2)\u001b[0m\n",
            "02:56:49 | \u001b[33mOverriding opt[\"num_epochs\"] to 2.0 (previously: 0.1)\u001b[0m\n",
            "02:56:49 | Using CUDA\n",
            "02:56:49 | loading dictionary from /content/ParlAI/data/models/blender/blender_90M/model.dict\n",
            "02:56:49 | num words = 54944\n",
            "02:56:49 | \u001b[33mDEPRECATED: XLM should only be used for backwards compatibility, as it involves a less-stable layernorm operation.\u001b[0m\n",
            "02:56:52 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "02:56:52 | Loading existing model params from /content/ParlAI/data/models/blender/blender_90M/model\n",
            "02:56:53 | Opt:\n",
            "02:56:53 |     activation: gelu\n",
            "02:56:53 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "02:56:53 |     adam_eps: 1e-08\n",
            "02:56:53 |     add_missing_turns: none\n",
            "02:56:53 |     add_p1_after_newln: False\n",
            "02:56:53 |     aggregate_micro: False\n",
            "02:56:53 |     allow_missing_init_opts: False\n",
            "02:56:53 |     attention_dropout: 0.0\n",
            "02:56:53 |     batchsize: 50\n",
            "02:56:53 |     beam_block_full_context: False\n",
            "02:56:53 |     beam_block_list_filename: None\n",
            "02:56:53 |     beam_block_ngram: 3\n",
            "02:56:53 |     beam_context_block_ngram: 3\n",
            "02:56:53 |     beam_delay: 30\n",
            "02:56:53 |     beam_length_penalty: 0.65\n",
            "02:56:53 |     beam_min_length: 20\n",
            "02:56:53 |     beam_size: 10\n",
            "02:56:53 |     betas: '[0.9, 0.999]'\n",
            "02:56:53 |     bpe_add_prefix_space: None\n",
            "02:56:53 |     bpe_debug: False\n",
            "02:56:53 |     bpe_dropout: None\n",
            "02:56:53 |     bpe_merge: None\n",
            "02:56:53 |     bpe_vocab: None\n",
            "02:56:53 |     checkpoint_activations: False\n",
            "02:56:53 |     chosen_topic_delimiter: '\\n'\n",
            "02:56:53 |     clearml_log: False\n",
            "02:56:53 |     clearml_project_name: ParlAI\n",
            "02:56:53 |     clearml_task_name: 'Default Task'\n",
            "02:56:53 |     compute_tokenized_bleu: False\n",
            "02:56:53 |     datapath: /content/ParlAI/data\n",
            "02:56:53 |     datatype: train\n",
            "02:56:53 |     delimiter: '\\n'\n",
            "02:56:53 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "02:56:53 |     dict_endtoken: __end__\n",
            "02:56:53 |     dict_file: /content/ParlAI/data/models/blender/blender_90M/model.dict\n",
            "02:56:53 |     dict_include_test: False\n",
            "02:56:53 |     dict_include_valid: False\n",
            "02:56:53 |     dict_initpath: None\n",
            "02:56:53 |     dict_language: english\n",
            "02:56:53 |     dict_loaded: True\n",
            "02:56:53 |     dict_lower: True\n",
            "02:56:53 |     dict_max_ngram_size: -1\n",
            "02:56:53 |     dict_maxexs: -1\n",
            "02:56:53 |     dict_maxtokens: -1\n",
            "02:56:53 |     dict_minfreq: 0\n",
            "02:56:53 |     dict_nulltoken: __null__\n",
            "02:56:53 |     dict_starttoken: __start__\n",
            "02:56:53 |     dict_textfields: text,labels\n",
            "02:56:53 |     dict_tokenizer: bpe\n",
            "02:56:53 |     dict_unktoken: __unk__\n",
            "02:56:53 |     display_examples: False\n",
            "02:56:53 |     download_path: None\n",
            "02:56:53 |     dropout: 0.1\n",
            "02:56:53 |     dynamic_batching: None\n",
            "02:56:53 |     embedding_projection: random\n",
            "02:56:53 |     embedding_size: 512\n",
            "02:56:53 |     embedding_type: random\n",
            "02:56:53 |     embeddings_scale: True\n",
            "02:56:53 |     eval_batchsize: None\n",
            "02:56:53 |     eval_dynamic_batching: None\n",
            "02:56:53 |     evaltask: None\n",
            "02:56:53 |     ffn_size: 2048\n",
            "02:56:53 |     final_extra_opt: \n",
            "02:56:53 |     force_fp16_tokens: True\n",
            "02:56:53 |     fp16: True\n",
            "02:56:53 |     fp16_impl: safe\n",
            "02:56:53 |     gpu: -1\n",
            "02:56:53 |     gpu_beam_blocking: False\n",
            "02:56:53 |     gradient_clip: 0.1\n",
            "02:56:53 |     hide_labels: False\n",
            "02:56:53 |     history_add_global_end_token: None\n",
            "02:56:53 |     history_reversed: False\n",
            "02:56:53 |     history_size: -1\n",
            "02:56:53 |     image_cropsize: 224\n",
            "02:56:53 |     image_mode: raw\n",
            "02:56:53 |     image_size: 256\n",
            "02:56:53 |     include_checked_sentence: True\n",
            "02:56:53 |     include_knowledge: True\n",
            "02:56:53 |     include_knowledge_separator: False\n",
            "02:56:53 |     inference: beam\n",
            "02:56:53 |     init_model: /checkpoint/parlai/zoo/new_reddit/newreddit_trained20190909_usedfordodeca/model\n",
            "02:56:53 |     init_opt: None\n",
            "02:56:53 |     interactive_mode: False\n",
            "02:56:53 |     invsqrt_lr_decay_gamma: -1\n",
            "02:56:53 |     is_debug: False\n",
            "02:56:53 |     label_truncate: 128\n",
            "02:56:53 |     label_type: response\n",
            "02:56:53 |     lambda_decay: 0.9\n",
            "02:56:53 |     learn_positional_embeddings: True\n",
            "02:56:53 |     learningrate: 0.0001\n",
            "02:56:53 |     load_from_checkpoint: True\n",
            "02:56:53 |     log_every_n_secs: 2\n",
            "02:56:53 |     log_every_n_steps: 50\n",
            "02:56:53 |     log_keep_fields: all\n",
            "02:56:53 |     loglevel: info\n",
            "02:56:53 |     lr_scheduler: reduceonplateau\n",
            "02:56:53 |     lr_scheduler_decay: 0.5\n",
            "02:56:53 |     lr_scheduler_patience: 3\n",
            "02:56:53 |     max_lr_steps: -1\n",
            "02:56:53 |     max_train_steps: -1\n",
            "02:56:53 |     max_train_time: -1\n",
            "02:56:53 |     metrics: default\n",
            "02:56:53 |     model: transformer/generator\n",
            "02:56:53 |     model_file: /content/ParlAI/data/models/blender/blender_90M/model\n",
            "02:56:53 |     model_parallel: False\n",
            "02:56:53 |     momentum: 0\n",
            "02:56:53 |     multitask_weights: '[1.0, 3.0, 3.0, 3.0]'\n",
            "02:56:53 |     mutators: None\n",
            "02:56:53 |     n_decoder_layers: -1\n",
            "02:56:53 |     n_encoder_layers: -1\n",
            "02:56:53 |     n_heads: 16\n",
            "02:56:53 |     n_layers: 8\n",
            "02:56:53 |     n_positions: 512\n",
            "02:56:53 |     n_segments: 0\n",
            "02:56:53 |     nesterov: True\n",
            "02:56:53 |     no_cuda: False\n",
            "02:56:53 |     num_epochs: 2.0\n",
            "02:56:53 |     num_topics: 5\n",
            "02:56:53 |     num_workers: 0\n",
            "02:56:53 |     numthreads: 1\n",
            "02:56:53 |     nus: [0.7]\n",
            "02:56:53 |     omega_bound: 0.3\n",
            "02:56:53 |     optimizer: adamax\n",
            "02:56:53 |     output_scaling: 1.0\n",
            "02:56:53 |     override: \"{'task': 'dailydialog', 'model_file': '/content/ParlAI/data/models/blender/blender_90M/model', 'short_final_eval': True, 'batchsize': 50, 'validation_max_exs': 100, 'learningrate': 0.0001, 'num_epochs': 2.0, 'model': 'transformer/generator'}\"\n",
            "02:56:53 |     p_reset: True\n",
            "02:56:53 |     parlai_home: /private/home/edinan/ParlAI\n",
            "02:56:53 |     person_tokens: False\n",
            "02:56:53 |     rank_candidates: False\n",
            "02:56:53 |     relu_dropout: 0.0\n",
            "02:56:53 |     save_after_valid: True\n",
            "02:56:53 |     save_every_n_secs: 60.0\n",
            "02:56:53 |     save_format: conversations\n",
            "02:56:53 |     seed: None\n",
            "02:56:53 |     share_word_embeddings: True\n",
            "02:56:53 |     short_final_eval: True\n",
            "02:56:53 |     show_advanced_args: False\n",
            "02:56:53 |     skip_generation: False\n",
            "02:56:53 |     special_tok_lst: None\n",
            "02:56:53 |     split_lines: False\n",
            "02:56:53 |     starttime: Feb10_07-25\n",
            "02:56:53 |     task: dailydialog\n",
            "02:56:53 |     teacher_seed: None\n",
            "02:56:53 |     temperature: 1.0\n",
            "02:56:53 |     tensorboard_log: False\n",
            "02:56:53 |     tensorboard_logdir: None\n",
            "02:56:53 |     text_truncate: 512\n",
            "02:56:53 |     topk: 10\n",
            "02:56:53 |     topp: 0.9\n",
            "02:56:53 |     train_experiencer_only: False\n",
            "02:56:53 |     truncate: -1\n",
            "02:56:53 |     update_freq: 1\n",
            "02:56:53 |     use_reply: label\n",
            "02:56:53 |     validation_cutoff: 1.0\n",
            "02:56:53 |     validation_every_n_epochs: 0.25\n",
            "02:56:53 |     validation_every_n_secs: -1\n",
            "02:56:53 |     validation_every_n_steps: -1\n",
            "02:56:53 |     validation_max_exs: 100\n",
            "02:56:53 |     validation_metric: ppl\n",
            "02:56:53 |     validation_metric_mode: min\n",
            "02:56:53 |     validation_patience: 15\n",
            "02:56:53 |     validation_share_agent: False\n",
            "02:56:53 |     variant: xlm\n",
            "02:56:53 |     verbose: False\n",
            "02:56:53 |     verbose_topk: -1\n",
            "02:56:53 |     wandb_entity: None\n",
            "02:56:53 |     wandb_log: False\n",
            "02:56:53 |     wandb_log_model: False\n",
            "02:56:53 |     wandb_name: None\n",
            "02:56:53 |     wandb_project: None\n",
            "02:56:53 |     warmup_rate: 0.0001\n",
            "02:56:53 |     warmup_updates: -1\n",
            "02:56:53 |     weight_decay: None\n",
            "02:56:53 |     world_logs: \n",
            "02:56:53 | Current ParlAI commit: 6c802418e93a51cbb746b011439ab783dd136de8\n",
            "02:56:53 | creating task(s): dailydialog\n",
            "[building data: /content/ParlAI/data/dailydialog]\n",
            "02:56:53 | Downloading http://parl.ai/downloads/dailydialog/dailydialog.tar.gz to /content/ParlAI/data/dailydialog/dailydialog.tar.gz\n",
            "Downloading dailydialog.tar.gz: 100% 2.72M/2.72M [00:01<00:00, 1.44MB/s]\n",
            "02:56:55 | training...\n",
            "02:56:56 | time:67631s total_exs:1591327 total_steps:339016 epochs:18.26 time_left:0s\n",
            "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  fp16_loss_scalar  gnorm  gpu_mem  llen  \\\n",
            "    5.36     1   268 491.3       0          0 91.61   50             32768  12.63    .2055 12.88   \n",
            "    loss    lr  ltpb  ltps  ltrunc  ltrunclen   ppl  token_acc  token_em  total_train_updates  \\\n",
            "   3.426 .0001   644  1180       0          0 30.77      .3820         0               339016   \n",
            "    tpb  tps   ups  \n",
            "    912 1672 1.841\n",
            "\n",
            "02:56:56 | num_epochs completed:2.0 time elapsed:67630.74951815605s\n",
            "02:56:57 | Using CUDA\n",
            "02:56:57 | loading dictionary from /content/ParlAI/data/models/blender/blender_90M/model.dict\n",
            "02:56:58 | num words = 54944\n",
            "02:56:59 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "02:56:59 | Loading existing model params from /content/ParlAI/data/models/blender/blender_90M/model\n",
            "02:57:00 | creating task(s): dailydialog\n",
            "02:57:00 | running eval: valid\n",
            "02:57:08 | eval completed in 8.02s\n",
            "02:57:08 | \u001b[1mvalid:\n",
            "    accuracy   bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  gen_n_toks  gpu_mem  \\\n",
            "           0 .0009376 22.81  1140 285.7       0          0 12.53  100 .1254       22.93   .09424   \n",
            "    llen  loss    lr  ltpb  ltps  ltrunc  ltrunclen   ppl  precision  recall  token_acc  token_em  \\\n",
            "   15.78 3.158 .0001   789 197.7       0          0 23.53      .1117   .1707      .4100         0   \n",
            "    total_train_updates  tpb   tps  \n",
            "                 339016 1930 483.4\n",
            "\u001b[0m\n",
            "02:57:08 | creating task(s): dailydialog\n",
            "02:57:08 | running eval: test\n",
            "02:57:16 | eval completed in 7.43s\n",
            "02:57:16 | \u001b[1mtest:\n",
            "    accuracy    bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs    f1  gen_n_toks  gpu_mem  \\\n",
            "           0 9.214e-07 18.74   937 253.4       0          0 13.52  100 .1145       22.94   .09424   \n",
            "    llen  loss    lr  ltpb  ltps  ltrunc  ltrunclen   ppl  precision  recall  token_acc  token_em  \\\n",
            "   13.14 2.968 .0001   657 177.7       0          0 19.46     .09401   .1781      .4285     .0100   \n",
            "    total_train_updates  tpb   tps  \n",
            "                 339016 1594 431.1\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python /content/ParlAI/parlai/scripts/train_model.py -t dailydialog -mf /content/ParlAI/data/models/blender/blender_90M/model --short-final-eval True --batchsize 50 -vme 100 -learningrate 1.0e-4 --num-epochs 2 --model transformer/generator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate model"
      ],
      "metadata": {
        "id": "Vuf370R9hP-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!parlai eval_model --task convai2 --model transformer/generator --model-file /content/ParlAI/data/models/blender/blender_90M/model --metrics bleu --num-examples 500 --batchsize 25 --datatype test --report-filename /content/results/Final_convai2_eval_report.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJ6tUiZaxCER",
        "outputId": "8843ff0e-b6c4-4b02-ca40-c07fafd642f7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-13 03:07:03.198877: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-13 03:07:03.198936: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-13 03:07:03.198964: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-13 03:07:04.380116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "03:07:06 | \u001b[33mOverriding opt[\"task\"] to convai2 (previously: dailydialog)\u001b[0m\n",
            "03:07:06 | \u001b[33mOverriding opt[\"metrics\"] to bleu (previously: default)\u001b[0m\n",
            "03:07:06 | \u001b[33mOverriding opt[\"batchsize\"] to 25 (previously: 50)\u001b[0m\n",
            "03:07:06 | \u001b[33mOverriding opt[\"datatype\"] to test (previously: train)\u001b[0m\n",
            "03:07:06 | Using CUDA\n",
            "03:07:06 | loading dictionary from /content/ParlAI/data/models/blender/blender_90M/model.dict\n",
            "03:07:06 | num words = 54944\n",
            "03:07:07 | \u001b[33mDEPRECATED: XLM should only be used for backwards compatibility, as it involves a less-stable layernorm operation.\u001b[0m\n",
            "03:07:10 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "03:07:10 | Loading existing model params from /content/ParlAI/data/models/blender/blender_90M/model\n",
            "03:07:10 | Opt:\n",
            "03:07:10 |     activation: gelu\n",
            "03:07:10 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "03:07:10 |     adam_eps: 1e-08\n",
            "03:07:10 |     add_missing_turns: none\n",
            "03:07:10 |     add_p1_after_newln: False\n",
            "03:07:10 |     aggregate_micro: False\n",
            "03:07:10 |     allow_missing_init_opts: False\n",
            "03:07:10 |     area_under_curve_class: None\n",
            "03:07:10 |     area_under_curve_digits: -1\n",
            "03:07:10 |     attention_dropout: 0.0\n",
            "03:07:10 |     batchsize: 25\n",
            "03:07:10 |     beam_block_full_context: False\n",
            "03:07:10 |     beam_block_list_filename: None\n",
            "03:07:10 |     beam_block_ngram: 3\n",
            "03:07:10 |     beam_context_block_ngram: 3\n",
            "03:07:10 |     beam_delay: 30\n",
            "03:07:10 |     beam_length_penalty: 0.65\n",
            "03:07:10 |     beam_min_length: 20\n",
            "03:07:10 |     beam_size: 10\n",
            "03:07:10 |     betas: '[0.9, 0.999]'\n",
            "03:07:10 |     bpe_add_prefix_space: None\n",
            "03:07:10 |     bpe_debug: False\n",
            "03:07:10 |     bpe_dropout: None\n",
            "03:07:10 |     bpe_merge: None\n",
            "03:07:10 |     bpe_vocab: None\n",
            "03:07:10 |     checkpoint_activations: False\n",
            "03:07:10 |     chosen_topic_delimiter: '\\n'\n",
            "03:07:10 |     clearml_log: False\n",
            "03:07:10 |     clearml_project_name: ParlAI\n",
            "03:07:10 |     clearml_task_name: 'Default Task'\n",
            "03:07:10 |     compute_tokenized_bleu: False\n",
            "03:07:10 |     datapath: /content/ParlAI/data\n",
            "03:07:10 |     datatype: test\n",
            "03:07:10 |     delimiter: '\\n'\n",
            "03:07:10 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "03:07:10 |     dict_endtoken: __end__\n",
            "03:07:10 |     dict_file: /content/ParlAI/data/models/blender/blender_90M/model.dict\n",
            "03:07:10 |     dict_include_test: False\n",
            "03:07:10 |     dict_include_valid: False\n",
            "03:07:10 |     dict_initpath: None\n",
            "03:07:10 |     dict_language: english\n",
            "03:07:10 |     dict_loaded: True\n",
            "03:07:10 |     dict_lower: True\n",
            "03:07:10 |     dict_max_ngram_size: -1\n",
            "03:07:10 |     dict_maxexs: -1\n",
            "03:07:10 |     dict_maxtokens: -1\n",
            "03:07:10 |     dict_minfreq: 0\n",
            "03:07:10 |     dict_nulltoken: __null__\n",
            "03:07:10 |     dict_starttoken: __start__\n",
            "03:07:10 |     dict_textfields: text,labels\n",
            "03:07:10 |     dict_tokenizer: bpe\n",
            "03:07:10 |     dict_unktoken: __unk__\n",
            "03:07:10 |     display_examples: False\n",
            "03:07:10 |     download_path: None\n",
            "03:07:10 |     dropout: 0.1\n",
            "03:07:10 |     dynamic_batching: None\n",
            "03:07:10 |     embedding_projection: random\n",
            "03:07:10 |     embedding_size: 512\n",
            "03:07:10 |     embedding_type: random\n",
            "03:07:10 |     embeddings_scale: True\n",
            "03:07:10 |     eval_batchsize: None\n",
            "03:07:10 |     eval_dynamic_batching: None\n",
            "03:07:10 |     evaltask: None\n",
            "03:07:10 |     ffn_size: 2048\n",
            "03:07:10 |     final_extra_opt: \n",
            "03:07:10 |     force_fp16_tokens: True\n",
            "03:07:10 |     fp16: True\n",
            "03:07:10 |     fp16_impl: safe\n",
            "03:07:10 |     gpu: -1\n",
            "03:07:10 |     gpu_beam_blocking: False\n",
            "03:07:10 |     gradient_clip: 0.1\n",
            "03:07:10 |     hide_labels: False\n",
            "03:07:10 |     history_add_global_end_token: None\n",
            "03:07:10 |     history_reversed: False\n",
            "03:07:10 |     history_size: -1\n",
            "03:07:10 |     image_cropsize: 224\n",
            "03:07:10 |     image_mode: raw\n",
            "03:07:10 |     image_size: 256\n",
            "03:07:10 |     include_checked_sentence: True\n",
            "03:07:10 |     include_knowledge: True\n",
            "03:07:10 |     include_knowledge_separator: False\n",
            "03:07:10 |     inference: beam\n",
            "03:07:10 |     init_model: /checkpoint/parlai/zoo/new_reddit/newreddit_trained20190909_usedfordodeca/model\n",
            "03:07:10 |     init_opt: None\n",
            "03:07:10 |     interactive_mode: False\n",
            "03:07:10 |     invsqrt_lr_decay_gamma: -1\n",
            "03:07:10 |     is_debug: False\n",
            "03:07:10 |     label_truncate: 128\n",
            "03:07:10 |     label_type: response\n",
            "03:07:10 |     lambda_decay: 0.9\n",
            "03:07:10 |     learn_positional_embeddings: True\n",
            "03:07:10 |     learningrate: 0.0001\n",
            "03:07:10 |     log_every_n_secs: 2\n",
            "03:07:10 |     log_every_n_steps: 50\n",
            "03:07:10 |     log_keep_fields: all\n",
            "03:07:10 |     loglevel: info\n",
            "03:07:10 |     lr_scheduler: reduceonplateau\n",
            "03:07:10 |     lr_scheduler_decay: 0.5\n",
            "03:07:10 |     lr_scheduler_patience: 3\n",
            "03:07:10 |     max_lr_steps: -1\n",
            "03:07:10 |     max_train_steps: -1\n",
            "03:07:10 |     max_train_time: -1\n",
            "03:07:10 |     metrics: bleu\n",
            "03:07:10 |     model: transformer/generator\n",
            "03:07:10 |     model_file: /content/ParlAI/data/models/blender/blender_90M/model\n",
            "03:07:10 |     model_parallel: False\n",
            "03:07:10 |     momentum: 0\n",
            "03:07:10 |     multitask_weights: '[1.0, 3.0, 3.0, 3.0]'\n",
            "03:07:10 |     mutators: None\n",
            "03:07:10 |     n_decoder_layers: -1\n",
            "03:07:10 |     n_encoder_layers: -1\n",
            "03:07:10 |     n_heads: 16\n",
            "03:07:10 |     n_layers: 8\n",
            "03:07:10 |     n_positions: 512\n",
            "03:07:10 |     n_segments: 0\n",
            "03:07:10 |     nesterov: True\n",
            "03:07:10 |     no_cuda: False\n",
            "03:07:10 |     num_epochs: 2.0\n",
            "03:07:10 |     num_examples: 500\n",
            "03:07:10 |     num_topics: 5\n",
            "03:07:10 |     num_workers: 0\n",
            "03:07:10 |     numthreads: 1\n",
            "03:07:10 |     nus: [0.7]\n",
            "03:07:10 |     omega_bound: 0.3\n",
            "03:07:10 |     optimizer: adamax\n",
            "03:07:10 |     output_scaling: 1.0\n",
            "03:07:10 |     override: \"{'task': 'convai2', 'model': 'transformer/generator', 'model_file': '/content/ParlAI/data/models/blender/blender_90M/model', 'metrics': 'bleu', 'num_examples': 500, 'batchsize': 25, 'datatype': 'test', 'report_filename': '/content/results/Final_convai2_eval_report.txt'}\"\n",
            "03:07:10 |     p_reset: True\n",
            "03:07:10 |     parlai_home: /private/home/edinan/ParlAI\n",
            "03:07:10 |     person_tokens: False\n",
            "03:07:10 |     rank_candidates: False\n",
            "03:07:10 |     relu_dropout: 0.0\n",
            "03:07:10 |     report_filename: /content/results/Final_convai2_eval_report.txt\n",
            "03:07:10 |     save_after_valid: True\n",
            "03:07:10 |     save_every_n_secs: 60.0\n",
            "03:07:10 |     save_format: conversations\n",
            "03:07:10 |     seed: None\n",
            "03:07:10 |     share_word_embeddings: True\n",
            "03:07:10 |     short_final_eval: True\n",
            "03:07:10 |     show_advanced_args: False\n",
            "03:07:10 |     skip_generation: False\n",
            "03:07:10 |     special_tok_lst: None\n",
            "03:07:10 |     split_lines: False\n",
            "03:07:10 |     starttime: Feb10_07-25\n",
            "03:07:10 |     task: convai2\n",
            "03:07:10 |     teacher_seed: None\n",
            "03:07:10 |     temperature: 1.0\n",
            "03:07:10 |     tensorboard_log: False\n",
            "03:07:10 |     tensorboard_logdir: None\n",
            "03:07:10 |     text_truncate: 512\n",
            "03:07:10 |     topk: 10\n",
            "03:07:10 |     topp: 0.9\n",
            "03:07:10 |     train_experiencer_only: False\n",
            "03:07:10 |     truncate: -1\n",
            "03:07:10 |     update_freq: 1\n",
            "03:07:10 |     use_reply: label\n",
            "03:07:10 |     validation_cutoff: 1.0\n",
            "03:07:10 |     validation_every_n_epochs: 0.25\n",
            "03:07:10 |     validation_every_n_secs: -1\n",
            "03:07:10 |     validation_every_n_steps: -1\n",
            "03:07:10 |     validation_max_exs: 100\n",
            "03:07:10 |     validation_metric: ppl\n",
            "03:07:10 |     validation_metric_mode: min\n",
            "03:07:10 |     validation_patience: 15\n",
            "03:07:10 |     validation_share_agent: False\n",
            "03:07:10 |     variant: xlm\n",
            "03:07:10 |     verbose: False\n",
            "03:07:10 |     verbose_topk: -1\n",
            "03:07:10 |     wandb_entity: None\n",
            "03:07:10 |     wandb_log: False\n",
            "03:07:10 |     wandb_log_model: False\n",
            "03:07:10 |     wandb_name: None\n",
            "03:07:10 |     wandb_project: None\n",
            "03:07:10 |     warmup_rate: 0.0001\n",
            "03:07:10 |     warmup_updates: -1\n",
            "03:07:10 |     weight_decay: None\n",
            "03:07:10 |     world_logs: \n",
            "03:07:10 | Current ParlAI commit: 6c802418e93a51cbb746b011439ab783dd136de8\n",
            "03:07:10 | Evaluating task convai2 using datatype test.\n",
            "03:07:10 | creating task(s): convai2\n",
            "03:07:10 | \u001b[33mWARNING: Test set not included. Setting datatype to valid.\u001b[0m\n",
            "03:07:10 | loading fbdialog data: /content/ParlAI/data/ConvAI2/valid_self_original.txt\n",
            "03:07:22 | 25.0% complete (125 / 500), 0:00:11 elapsed, 0:00:34 eta\n",
            "    accuracy  bleu-1  bleu-2  bleu-3  bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n",
            "           0   .1963   .0896  .04085   .0168 120.6  3016  1325       0          0 10.99  125   \n",
            "      f1  gen_n_toks  gpu_mem  llen  loss  ltpb  ltps  ltrunc  ltrunclen   ppl  precision  recall  \\\n",
            "   .2304       22.52    .1463 13.98 2.244 349.4 153.5       0          0 9.433      .1974   .2887   \n",
            "    token_acc  token_em  tpb  tps  \n",
            "        .4940         0 3366 1479\n",
            "03:07:32 | 45.0% complete (225 / 500), 0:00:21 elapsed, 0:00:27 eta\n",
            "    accuracy  bleu-1  bleu-2  bleu-3  bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n",
            "           0   .1779  .06737  .02533 .009334 144.6  3615  1498       0          0 10.36  225   \n",
            "      f1  gen_n_toks  gpu_mem  llen  loss  ltpb  ltps  ltrunc  ltrunclen   ppl  precision  recall  \\\n",
            "   .2106       22.53    .1998 13.74 2.385 343.4 142.3       0          0 10.86      .1785   .2718   \n",
            "    token_acc  token_em  tpb  tps  \n",
            "        .4727         0 3959 1640\n",
            "03:07:44 | 70.0% complete (350 / 500), 0:00:33 elapsed, 0:00:14 eta\n",
            "    accuracy  bleu-1  bleu-2  bleu-3  bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n",
            "           0   .1697  .06252  .02442  .00943 148.8  3721  1563       0          0  10.5  350   \n",
            "      f1  gen_n_toks  gpu_mem  llen  loss  ltpb  ltps  ltrunc  ltrunclen   ppl  precision  recall  \\\n",
            "   .2019       22.56    .1704 13.52  2.49   338   142       0          0 12.06      .1705   .2632   \n",
            "    token_acc  token_em  tpb  tps  \n",
            "        .4620         0 4059 1705\n",
            "03:07:55 | 95.0% complete (475 / 500), 0:00:45 elapsed, 0:00:02 eta\n",
            "    accuracy  bleu-1  bleu-2  bleu-3  bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n",
            "           0   .1651  .05876  .02258 .009127 147.9  3696  1559       0          0 10.54  475   \n",
            "      f1  gen_n_toks  gpu_mem  llen  loss  ltpb  ltps  ltrunc  ltrunclen   ppl  precision  recall  \\\n",
            "   .1971       22.53    .1834  13.5 2.499 337.6 142.3       0          0 12.17      .1662   .2581   \n",
            "    token_acc  token_em  tpb  tps  \n",
            "        .4609         0 4034 1701\n",
            "03:07:58 | \u001b[1mReport for convai2:\n",
            "    accuracy  bleu-1  bleu-2  bleu-3  bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n",
            "           0   .1627  .05713  .02145 .008671 148.9  3724  1572       0          0 10.55  500   \n",
            "      f1  gen_n_toks  gpu_mem  llen  loss  ltpb  ltps  ltrunc  ltrunclen   ppl  precision  recall  \\\n",
            "   .1941       22.52    .1441 13.55 2.508 338.6   143       0          0 12.28      .1639   .2537   \n",
            "    token_acc  token_em  tpb  tps  \n",
            "        .4614         0 4062 1715\u001b[0m\n",
            "03:07:58 | Finished evaluating tasks ['convai2'] using datatype test\n",
            "    accuracy  bleu-1  bleu-2  bleu-3  bleu-4  clen  ctpb  ctps  ctrunc  ctrunclen  exps  exs  \\\n",
            "           0   .1627  .05713  .02145 .008671 148.9  3724  1572       0          0 10.55  500   \n",
            "      f1  gen_n_toks  gpu_mem  llen  loss  ltpb  ltps  ltrunc  ltrunclen   ppl  precision  recall  \\\n",
            "   .1941       22.52    .1441 13.55 2.508 338.6   143       0          0 12.28      .1639   .2537   \n",
            "    token_acc  token_em  tpb  tps  \n",
            "        .4614         0 4062 1715\n",
            "03:07:58 | Saving model report to /content/results/Final_convai2_eval_report.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG8QxoQRazYj",
        "outputId": "7b8f29cd-70e9-4095-ffeb-af530655febd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/results/ (stored 0%)\n",
            "  adding: content/results/Final_WoW_eval_report.txt (deflated 68%)\n",
            "  adding: content/results/Final_DD_eval_report.txt (deflated 68%)\n",
            "  adding: content/results/Final_convai2_eval_report.txt (deflated 68%)\n",
            "  adding: content/results/Final_BST_eval_report.txt (deflated 68%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r \"/content/results_nlp_final.zip\" \"/content/results\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interact with the model"
      ],
      "metadata": {
        "id": "HROvkHhvhS7Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Oq0HqyAI22t",
        "outputId": "f53ff934-590b-4bd2-a59a-7c569bb42fcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15:56:42 | \u001b[33mOverriding opt[\"model_file\"] to /content/drive/MyDrive/blender/content/ParlAI/data/models/blender/blender_90M/model (previously: /content/ParlAI/data/models/blender/blender_90M/model)\u001b[0m\n",
            "15:56:42 | Using CUDA\n",
            "15:56:42 | loading dictionary from /content/drive/MyDrive/blender/content/ParlAI/data/models/blender/blender_90M/model.dict\n",
            "15:56:51 | num words = 54944\n",
            "15:56:52 | TransformerGenerator: full interactive mode on.\n",
            "15:56:52 | \u001b[33mDEPRECATED: XLM should only be used for backwards compatibility, as it involves a less-stable layernorm operation.\u001b[0m\n",
            "15:56:57 | Total parameters: 87,508,992 (87,508,992 trainable)\n",
            "15:56:57 | Loading existing model params from /content/drive/MyDrive/blender/content/ParlAI/data/models/blender/blender_90M/model\n",
            "15:57:39 | Opt:\n",
            "15:57:39 |     activation: gelu\n",
            "15:57:39 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "15:57:39 |     adam_eps: 1e-08\n",
            "15:57:39 |     add_p1_after_newln: False\n",
            "15:57:39 |     aggregate_micro: False\n",
            "15:57:39 |     allow_missing_init_opts: False\n",
            "15:57:39 |     attention_dropout: 0.0\n",
            "15:57:39 |     batchsize: 16\n",
            "15:57:39 |     beam_block_full_context: False\n",
            "15:57:39 |     beam_block_list_filename: None\n",
            "15:57:39 |     beam_block_ngram: 3\n",
            "15:57:39 |     beam_context_block_ngram: 3\n",
            "15:57:39 |     beam_delay: 30\n",
            "15:57:39 |     beam_length_penalty: 0.65\n",
            "15:57:39 |     beam_min_length: 20\n",
            "15:57:39 |     beam_size: 10\n",
            "15:57:39 |     betas: '[0.9, 0.999]'\n",
            "15:57:39 |     bpe_add_prefix_space: None\n",
            "15:57:39 |     bpe_debug: False\n",
            "15:57:39 |     bpe_dropout: None\n",
            "15:57:39 |     bpe_merge: None\n",
            "15:57:39 |     bpe_vocab: None\n",
            "15:57:39 |     checkpoint_activations: False\n",
            "15:57:39 |     clearml_log: False\n",
            "15:57:39 |     clearml_project_name: ParlAI\n",
            "15:57:39 |     clearml_task_name: 'Default Task'\n",
            "15:57:39 |     compute_tokenized_bleu: False\n",
            "15:57:39 |     datapath: /content/ParlAI/data\n",
            "15:57:39 |     datatype: train\n",
            "15:57:39 |     delimiter: '\\n'\n",
            "15:57:39 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "15:57:39 |     dict_endtoken: __end__\n",
            "15:57:39 |     dict_file: /content/drive/MyDrive/blender/content/ParlAI/data/models/blender/blender_90M/model.dict\n",
            "15:57:39 |     dict_include_test: False\n",
            "15:57:39 |     dict_include_valid: False\n",
            "15:57:39 |     dict_initpath: None\n",
            "15:57:39 |     dict_language: english\n",
            "15:57:39 |     dict_loaded: True\n",
            "15:57:39 |     dict_lower: True\n",
            "15:57:39 |     dict_max_ngram_size: -1\n",
            "15:57:39 |     dict_maxexs: -1\n",
            "15:57:39 |     dict_maxtokens: -1\n",
            "15:57:39 |     dict_minfreq: 0\n",
            "15:57:39 |     dict_nulltoken: __null__\n",
            "15:57:39 |     dict_starttoken: __start__\n",
            "15:57:39 |     dict_textfields: text,labels\n",
            "15:57:39 |     dict_tokenizer: bpe\n",
            "15:57:39 |     dict_unktoken: __unk__\n",
            "15:57:39 |     display_add_fields: \n",
            "15:57:39 |     display_examples: False\n",
            "15:57:39 |     display_prettify: False\n",
            "15:57:39 |     download_path: None\n",
            "15:57:39 |     dropout: 0.1\n",
            "15:57:39 |     dynamic_batching: None\n",
            "15:57:39 |     embedding_projection: random\n",
            "15:57:39 |     embedding_size: 512\n",
            "15:57:39 |     embedding_type: random\n",
            "15:57:39 |     embeddings_scale: True\n",
            "15:57:39 |     eval_batchsize: None\n",
            "15:57:39 |     eval_dynamic_batching: None\n",
            "15:57:39 |     evaltask: None\n",
            "15:57:39 |     ffn_size: 2048\n",
            "15:57:39 |     final_extra_opt: \n",
            "15:57:39 |     force_fp16_tokens: True\n",
            "15:57:39 |     fp16: True\n",
            "15:57:39 |     fp16_impl: safe\n",
            "15:57:39 |     gpu: -1\n",
            "15:57:39 |     gpu_beam_blocking: False\n",
            "15:57:39 |     gradient_clip: 0.1\n",
            "15:57:39 |     hide_labels: False\n",
            "15:57:39 |     history_add_global_end_token: None\n",
            "15:57:39 |     history_reversed: False\n",
            "15:57:39 |     history_size: -1\n",
            "15:57:39 |     image_cropsize: 224\n",
            "15:57:39 |     image_mode: raw\n",
            "15:57:39 |     image_size: 256\n",
            "15:57:39 |     include_checked_sentence: True\n",
            "15:57:39 |     include_knowledge: True\n",
            "15:57:39 |     include_knowledge_separator: False\n",
            "15:57:39 |     inference: beam\n",
            "15:57:39 |     init_model: /checkpoint/parlai/zoo/new_reddit/newreddit_trained20190909_usedfordodeca/model\n",
            "15:57:39 |     init_opt: None\n",
            "15:57:39 |     interactive_mode: True\n",
            "15:57:39 |     interactive_task: True\n",
            "15:57:39 |     invsqrt_lr_decay_gamma: -1\n",
            "15:57:39 |     is_debug: False\n",
            "15:57:39 |     label_truncate: 128\n",
            "15:57:39 |     label_type: response\n",
            "15:57:39 |     lambda_decay: 0.9\n",
            "15:57:39 |     learn_positional_embeddings: True\n",
            "15:57:39 |     learningrate: 7.5e-06\n",
            "15:57:39 |     local_human_candidates_file: None\n",
            "15:57:39 |     log_every_n_secs: 2\n",
            "15:57:39 |     log_every_n_steps: 50\n",
            "15:57:39 |     log_keep_fields: all\n",
            "15:57:39 |     loglevel: info\n",
            "15:57:39 |     lr_scheduler: reduceonplateau\n",
            "15:57:39 |     lr_scheduler_decay: 0.5\n",
            "15:57:39 |     lr_scheduler_patience: 3\n",
            "15:57:39 |     max_lr_steps: -1\n",
            "15:57:39 |     max_train_steps: -1\n",
            "15:57:39 |     max_train_time: -1\n",
            "15:57:39 |     metrics: default\n",
            "15:57:39 |     model: transformer/generator\n",
            "15:57:39 |     model_file: /content/drive/MyDrive/blender/content/ParlAI/data/models/blender/blender_90M/model\n",
            "15:57:39 |     model_parallel: False\n",
            "15:57:39 |     momentum: 0\n",
            "15:57:39 |     multitask_weights: '[1.0, 3.0, 3.0, 3.0]'\n",
            "15:57:39 |     mutators: None\n",
            "15:57:39 |     n_decoder_layers: -1\n",
            "15:57:39 |     n_encoder_layers: -1\n",
            "15:57:39 |     n_heads: 16\n",
            "15:57:39 |     n_layers: 8\n",
            "15:57:39 |     n_positions: 512\n",
            "15:57:39 |     n_segments: 0\n",
            "15:57:39 |     nesterov: True\n",
            "15:57:39 |     no_cuda: False\n",
            "15:57:39 |     num_epochs: 4.0\n",
            "15:57:39 |     num_topics: 5\n",
            "15:57:39 |     num_workers: 0\n",
            "15:57:39 |     numthreads: 1\n",
            "15:57:39 |     nus: [0.7]\n",
            "15:57:39 |     omega_bound: 0.3\n",
            "15:57:39 |     optimizer: adamax\n",
            "15:57:39 |     outfile: \n",
            "15:57:39 |     output_scaling: 1.0\n",
            "15:57:39 |     override: \"{'task': 'dailydialog', 'model': 'transformer/generator', 'model_file': '/content/drive/MyDrive/blender/content/ParlAI/data/models/blender/blender_90M/model'}\"\n",
            "15:57:39 |     p_reset: True\n",
            "15:57:39 |     parlai_home: /private/home/edinan/ParlAI\n",
            "15:57:39 |     person_tokens: False\n",
            "15:57:39 |     rank_candidates: False\n",
            "15:57:39 |     relu_dropout: 0.0\n",
            "15:57:39 |     save_after_valid: True\n",
            "15:57:39 |     save_every_n_secs: 60.0\n",
            "15:57:39 |     save_format: conversations\n",
            "15:57:39 |     seed: None\n",
            "15:57:39 |     share_word_embeddings: True\n",
            "15:57:39 |     short_final_eval: False\n",
            "15:57:39 |     show_advanced_args: False\n",
            "15:57:39 |     single_turn: False\n",
            "15:57:39 |     skip_generation: False\n",
            "15:57:39 |     special_tok_lst: None\n",
            "15:57:39 |     split_lines: False\n",
            "15:57:39 |     starttime: Feb10_07-25\n",
            "15:57:39 |     task: dailydialog\n",
            "15:57:39 |     teacher_seed: None\n",
            "15:57:39 |     temperature: 1.0\n",
            "15:57:39 |     tensorboard_log: False\n",
            "15:57:39 |     tensorboard_logdir: None\n",
            "15:57:39 |     text_truncate: 512\n",
            "15:57:39 |     topk: 10\n",
            "15:57:39 |     topp: 0.9\n",
            "15:57:39 |     train_experiencer_only: False\n",
            "15:57:39 |     truncate: -1\n",
            "15:57:39 |     update_freq: 1\n",
            "15:57:39 |     use_reply: label\n",
            "15:57:39 |     validation_cutoff: 1.0\n",
            "15:57:39 |     validation_every_n_epochs: 0.25\n",
            "15:57:39 |     validation_every_n_secs: -1\n",
            "15:57:39 |     validation_every_n_steps: -1\n",
            "15:57:39 |     validation_max_exs: 20000\n",
            "15:57:39 |     validation_metric: ppl\n",
            "15:57:39 |     validation_metric_mode: min\n",
            "15:57:39 |     validation_patience: 15\n",
            "15:57:39 |     validation_share_agent: False\n",
            "15:57:39 |     variant: xlm\n",
            "15:57:39 |     verbose: False\n",
            "15:57:39 |     wandb_entity: None\n",
            "15:57:39 |     wandb_log: False\n",
            "15:57:39 |     wandb_log_model: False\n",
            "15:57:39 |     wandb_name: None\n",
            "15:57:39 |     wandb_project: None\n",
            "15:57:39 |     warmup_rate: 0.0001\n",
            "15:57:39 |     warmup_updates: -1\n",
            "15:57:39 |     weight_decay: None\n",
            "15:57:39 |     world_logs: \n",
            "15:57:39 | Current ParlAI commit: d921d22902d0ffb9c0c887cc1c315dacc6de0d80\n",
            "15:57:39 | Current internal commit: d921d22902d0ffb9c0c887cc1c315dacc6de0d80\n",
            "15:57:39 | Current fb commit: d921d22902d0ffb9c0c887cc1c315dacc6de0d80\n",
            "\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n",
            "15:57:39 | creating task(s): dailydialog\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m hi\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mhi , how are you today ? i just got back from a long day of work , how about you ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I am good\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mthat ' s good to hear . what do you do for a living , if you don ' t mind me asking ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m student\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1moh , i see . what are you going to school for ? i ' m a student as well .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m PhD\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1moh , cool . i ' ve always wanted to go to college , but it ' s too expensive .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m yeah that's true\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mwhat are your plans for the rest of your life ? do you have any other hobbies ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I will continue working in research\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1moh , that sounds interesting . what kind of research are you interested in ? i hope you enjoy it .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m yeah I work in machine learning. I like it\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1moh , wow . that sounds like a lot of work . i wish i had more time to do research .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m what are you studying?\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi am studying computer science . i hope i can get a job working on something like that one day .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m cool. what kind of job are you looking for?\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi am not sure yet . i am hoping to find a job that will allow me to do some of my research .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m what field of research are you interested in?\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi am interested in computer science , but i also want to get a degree in something like computer engineering .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m oh nice\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1myeah , i think i ' ll go for it . what else do you like to do for fun ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I play video games\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1moh , nice ! i like playing video games too . what ' s your favorite game to play ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m call of duty\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1moh , yes , i love that game too . do you play on xbox or playstation 4 or xbox one ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m xbox\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1moh , me too ! i love playing that game . what is your favorite part of the game ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m the story\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1moh , yeah , that is my favorite part too . i also like the story of the first one .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I like modern warfare\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1moh , what is that ? i haven ' t played it in a while . i used to play world at war .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m yeah that's good too\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1myeah , it was really fun . i think it was the first game to have a story like that .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m that's true\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1myeah , and i think that is why i like that game so much . it is so different from other games .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m yeah I also like god of war\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi have never played that one . i will have to check it out . thanks for the conversation !\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m Do you watch movies?\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi like to watch movies when i can . what about you ? are you a fan of movies ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m yeah I like horror movies\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi love horror movies . i especially like the ones that are set in the real world . have you seen that one ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m which one?\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi ' m not sure which one you are talking about . i just know that it is set in real life .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I like hereditary\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1moh , i ' ve never heard of it . is it a horror movie ? i know it is based on a true story .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m It's a horror movie but its not based on a true story\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1moh , okay . that is what i was thinking of . thank you for the reccomendation .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m lets talk about sports\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1moh , sure . i love sports . i watch a lot of football . what do you do for a living ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m which is your favorite team?\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi don ' t really have a favorite team . i do like the cowboys though . what are your favorite teams ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m New york giants\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mnice ! do you have any other hobbies ? i like going to the games with my family .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m which games?\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mall kinds of games . my favorite team is the texans . they are my favorite . you ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m EXIT\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1moh , ok . have a great day ! have a good one ! ! ! lol ! !\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m HI\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mhow are you doing today ? i hope you have a wonderful day ! thanks for chatting with me !\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m Should people be afraid of AI?\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi am not afraid of them . i am more afraid of people who think they are smarter than they are .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m what do you wanna talk about?\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1manything you would like to know about me . i ' ll tell you what i want to know .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I am all alone\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi am sorry to hear that . i hope things get better for you and you will feel better .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m i have two dogs and a rabbit.\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi have a dog and a cat . what kind of rabbit is it ? i want a dog .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m i like to listen to music.\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mme too . i like listening to music when i go to the movies . do you like movies ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m you're freaking me out\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mwhat are you freaking out about ? i just told you about my dogs and rabbit . you said you like music .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m talk about the weather\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1mi love the weather . it is the best . what is the weather like where you are from ?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m i said the weather. i didn't say corona virus.\n",
            "\u001b[0;34m[TransformerGenerator]:\u001b[0;0m \u001b[1moh , sorry . i thought you were talking about corona . i have never heard that name before .\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m "
          ]
        }
      ],
      "source": [
        "!python /content/ParlAI/parlai/scripts/interactive.py -t dailydialog -model transformer/generator -mf /content/drive/MyDrive/blender/content/ParlAI/data/models/blender/blender_90M/model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3wRya_R_74d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4b982a-a11c-4cac-d3e7-02f0c379b57c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/ParlAI/results_nlp_WoW.zip': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mv  \"/content/ParlAI/results_nlp_WoW.zip\" \"/content/ParlAI/results_wow\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_aEo2mjACSk",
        "outputId": "bef2f7d8-199a-4177-9644-37bc1728d2ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/ParlAI/Bsmall90_4epoch (2).zip\n",
            "   creating: /content/drive/MyDrive/BB4ep/content/tune_blenderbot/tune_blenderbot/Checkpoint/checkpoint-2000/\n",
            "  inflating: /content/drive/MyDrive/BB4ep/content/tune_blenderbot/tune_blenderbot/Checkpoint/checkpoint-2000/pytorch_model.bin  \n",
            "  inflating: /content/drive/MyDrive/BB4ep/content/tune_blenderbot/tune_blenderbot/Checkpoint/checkpoint-2000/optimizer.pt  \n",
            "  inflating: /content/drive/MyDrive/BB4ep/content/tune_blenderbot/tune_blenderbot/Checkpoint/checkpoint-2000/merges.txt  \n",
            "  inflating: /content/drive/MyDrive/BB4ep/content/tune_blenderbot/tune_blenderbot/Checkpoint/checkpoint-2000/rng_state.pth  \n",
            "  inflating: /content/drive/MyDrive/BB4ep/content/tune_blenderbot/tune_blenderbot/Checkpoint/checkpoint-2000/training_args.bin  \n",
            "  inflating: /content/drive/MyDrive/BB4ep/content/tune_blenderbot/tune_blenderbot/Checkpoint/checkpoint-2000/tokenizer_config.json  \n",
            "  inflating: /content/drive/MyDrive/BB4ep/content/tune_blenderbot/tune_blenderbot/Checkpoint/checkpoint-2000/vocab.json  \n",
            "  inflating: /content/drive/MyDrive/BB4ep/content/tune_blenderbot/tune_blenderbot/Checkpoint/checkpoint-2000/trainer_state.json  \n",
            "  inflating: /content/drive/MyDrive/BB4ep/content/tune_blenderbot/tune_blenderbot/Checkpoint/checkpoint-2000/special_tokens_map.json  \n",
            "  inflating: /content/drive/MyDrive/BB4ep/content/tune_blenderbot/tune_blenderbot/Checkpoint/checkpoint-2000/scheduler.pt  \n",
            "  inflating: /content/drive/MyDrive/BB4ep/content/tune_blenderbot/tune_blenderbot/Checkpoint/checkpoint-2000/generation_config.json  \n",
            "  inflating: /content/drive/MyDrive/BB4ep/content/tune_blenderbot/tune_blenderbot/Checkpoint/checkpoint-2000/config.json  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/ParlAI/Bsmall90_4epoch (2).zip\" -d \"/content/drive/MyDrive/BB4ep\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMiYVjhcGDL2",
        "outputId": "cf9d717c-c13b-4545-86ab-e4798aa649d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-164c354b-68e6-9730-afc8-3de828649d13)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scripts for generating plots"
      ],
      "metadata": {
        "id": "DYbKfb_AhbwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-whitegrid')\n",
        "import numpy as np\n",
        "BST_loss=[2.651872360277538,2.6701974318034556,2.6695504038430915,2.6667166632283763,2.664651710788082,2.665770380960113]\n",
        "#DD_loss=[2.9318,\t2.9673,\t2.9143,\t2.8746,\t2.8594,\t2.8514,\t2.4618]\n",
        "wow_loss=[2.8262474074695283,\t2.878945535541381,2.8798144036891475,2.8772246908021453,2.8766204575164207,2.87725445972193]\n",
        "#BST_loss=[2.6355,\t2.7283,\t2.6643,\t2.6900,\t2.7208,\t2.7490,\t2.9414]\n",
        "\n",
        "\n",
        "DD_f1=[0.1238,\t0.1382,\t0.1396,\t0.1361,\t0.1414,\t0.1552]\n",
        "BST_f1=[0.1658,\t0.1656,\t0.1684,\t0.1661,\t0.1654,\t0.1594]\n",
        "x_axis = [1,2,3,4,10,20]\n",
        "\n",
        "plt.plot(x_axis,wow_loss, 'ro', label = \"WoW\")\n",
        "plt.plot(x_axis,BST_loss,'gv',label = \"BST\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zw_WTSmTXtmB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "eab1480f-fc9e-4474-c09a-8f8f549eb89f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-56-16fff967b1f3>:2: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
            "  plt.style.use('seaborn-whitegrid')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "gpuClass": "premium"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}